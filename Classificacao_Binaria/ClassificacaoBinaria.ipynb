{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificação binária: Base breast cancer**"
      ],
      "metadata": {
        "id": "IFvCKJqwhx99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6976fOBjhrhA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_3ey81e-irrc",
        "outputId": "128f4ce1-c756-426f-9e54-3169f5556086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0786eee-825d-4642-94cf-af10c0b7d80d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0786eee-825d-4642-94cf-af10c0b7d80d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0786eee-825d-4642-94cf-af10c0b7d80d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0786eee-825d-4642-94cf-af10c0b7d80d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgudgFNni8VQ",
        "outputId": "8614431b-6696-4f51-8112-d9cb16c2696e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe = pd.read_csv('/content/saidas_breast.csv')\n",
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HbYaqyGci2aM",
        "outputId": "4eae0a05-c689-4c4e-a709-e9bea8b4491b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfbc798b-b075-4068-8707-e4f2614cb8f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfbc798b-b075-4068-8707-e4f2614cb8f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfbc798b-b075-4068-8707-e4f2614cb8f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfbc798b-b075-4068-8707-e4f2614cb8f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbH7kiS4jEvI",
        "outputId": "6bec8393-a13e-4b07-df9f-2bedb8abbae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9XGqVy4YjPIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores,classe, test_size=0.25)"
      ],
      "metadata": {
        "id": "D6uY6JX-jcqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_treinamento.shape, previsores_teste.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOcZpCSaj_d0",
        "outputId": "28f92ae0-6dc6-4fcb-bd65-9f4232de6da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((426, 30), (143, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe_treinamento.shape, classe_teste.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQY32bdhkHT8",
        "outputId": "32cdcffc-00ac-4cbf-f86f-116ff4d9fe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((426, 1), (143, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estrutura da rede neural**"
      ],
      "metadata": {
        "id": "cQTsbmQcknSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "TYkk5x7JkrKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "KElxBTkJkyzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Camadas densas\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "4TmV_Nzrk_fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = Sequential()"
      ],
      "metadata": {
        "id": "A8ImeoO8lVW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# previsores\n",
        "#units (quantos neurones farão parte da camada oculta (numero de entradas (30) + número de saída sendo zero ou um então vai ser (1) dividido por 2  = 15.5) )\n",
        "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))"
      ],
      "metadata": {
        "id": "qouQK1wFlZLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classificadores\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "KGrgp5b36S8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuração e execução da rede neural**"
      ],
      "metadata": {
        "id": "PAds8L3ZBXSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['binary_accuracy'])"
      ],
      "metadata": {
        "id": "yXG7wRfWBb3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMlpOGPOOMeI",
        "outputId": "3b087dfd-16b9-4999-d2e0-fda0075db945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 2ms/step - loss: 11.2996 - binary_accuracy: 0.6291\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.3667 - binary_accuracy: 0.7277\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.9802 - binary_accuracy: 0.7746\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3866 - binary_accuracy: 0.8638\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3891 - binary_accuracy: 0.8991\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2727 - binary_accuracy: 0.9085\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2501 - binary_accuracy: 0.9014\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3134 - binary_accuracy: 0.8897\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3892 - binary_accuracy: 0.8732\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2632 - binary_accuracy: 0.8967\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2909 - binary_accuracy: 0.9061\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3219 - binary_accuracy: 0.8920\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2959 - binary_accuracy: 0.8967\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7495 - binary_accuracy: 0.8427\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7727 - binary_accuracy: 0.8568\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2806 - binary_accuracy: 0.9085\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3084 - binary_accuracy: 0.8920\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2585 - binary_accuracy: 0.9038\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3616 - binary_accuracy: 0.8873\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3919 - binary_accuracy: 0.8826\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3518 - binary_accuracy: 0.8826\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4598 - binary_accuracy: 0.8685\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3785 - binary_accuracy: 0.8850\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8967\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2861 - binary_accuracy: 0.9155\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3852 - binary_accuracy: 0.9061\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5217 - binary_accuracy: 0.8709\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2484 - binary_accuracy: 0.9038\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2627 - binary_accuracy: 0.9296\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5526 - binary_accuracy: 0.8685\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2563 - binary_accuracy: 0.9155\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2483 - binary_accuracy: 0.9366\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2122 - binary_accuracy: 0.9249\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4013 - binary_accuracy: 0.9061\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5401 - binary_accuracy: 0.8732\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4613 - binary_accuracy: 0.8779\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3249 - binary_accuracy: 0.8944\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5787 - binary_accuracy: 0.8685\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2915 - binary_accuracy: 0.9085\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2453 - binary_accuracy: 0.9225\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2638 - binary_accuracy: 0.9178\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2472 - binary_accuracy: 0.9366\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3962 - binary_accuracy: 0.8920\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3199 - binary_accuracy: 0.9108\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2784 - binary_accuracy: 0.9178\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.2080 - binary_accuracy: 0.9225\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2483 - binary_accuracy: 0.9108\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2441 - binary_accuracy: 0.9155\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2385 - binary_accuracy: 0.9272\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2745 - binary_accuracy: 0.9272\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2685 - binary_accuracy: 0.9225\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2687 - binary_accuracy: 0.9272\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2002 - binary_accuracy: 0.9319\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3201 - binary_accuracy: 0.9108\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3901 - binary_accuracy: 0.9085\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4501 - binary_accuracy: 0.8850\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2719 - binary_accuracy: 0.9155\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4799 - binary_accuracy: 0.8850\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2762 - binary_accuracy: 0.8944\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2155 - binary_accuracy: 0.9249\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3222 - binary_accuracy: 0.8991\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2750 - binary_accuracy: 0.9155\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4339 - binary_accuracy: 0.8897\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3019 - binary_accuracy: 0.9061\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2494 - binary_accuracy: 0.9296\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1826 - binary_accuracy: 0.9437\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2223 - binary_accuracy: 0.9272\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2611 - binary_accuracy: 0.9108\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2749 - binary_accuracy: 0.9155\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2324 - binary_accuracy: 0.9272\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2576 - binary_accuracy: 0.9178\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2334 - binary_accuracy: 0.9366\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2265 - binary_accuracy: 0.9131\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2883 - binary_accuracy: 0.9085\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3092 - binary_accuracy: 0.9038\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2390 - binary_accuracy: 0.9225\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1792 - binary_accuracy: 0.9413\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1649 - binary_accuracy: 0.9413\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2928 - binary_accuracy: 0.9131\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3563 - binary_accuracy: 0.9038\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2949 - binary_accuracy: 0.8991\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2090 - binary_accuracy: 0.9249\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3366 - binary_accuracy: 0.9155\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1890 - binary_accuracy: 0.9249\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1999 - binary_accuracy: 0.9460\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1900 - binary_accuracy: 0.9460\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2242 - binary_accuracy: 0.9366\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2470 - binary_accuracy: 0.9178\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4619 - binary_accuracy: 0.8897\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2335 - binary_accuracy: 0.9413\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1663 - binary_accuracy: 0.9531\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1987 - binary_accuracy: 0.9437\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1511 - binary_accuracy: 0.9460\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2464 - binary_accuracy: 0.9155\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2757 - binary_accuracy: 0.9249\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1987 - binary_accuracy: 0.9249\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2087 - binary_accuracy: 0.9249\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2719 - binary_accuracy: 0.9038\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2878 - binary_accuracy: 0.9178\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4000 - binary_accuracy: 0.9038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f696ed0d6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Previsões com a rede neural**"
      ],
      "metadata": {
        "id": "ZYePejZfROb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previssoes = classificador.predict(previsores_teste)"
      ],
      "metadata": {
        "id": "Q2TMRaQZQTTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previssoes = (previssoes > 0.5)"
      ],
      "metadata": {
        "id": "BkNn1zORSEvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previssoes "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8lwt2MASbeI",
        "outputId": "cf1eae33-37d7-4a69-a5c6-69b9e3b80157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8AwdHCIWSHtk",
        "outputId": "599c26e7-af93-45c5-d3d7-9cc24dcbc741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0\n",
              "512  0\n",
              "459  1\n",
              "373  0\n",
              "343  0\n",
              "202  0\n",
              "..  ..\n",
              "32   0\n",
              "77   0\n",
              "142  1\n",
              "29   0\n",
              "146  0\n",
              "\n",
              "[143 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d17488e-061c-4a91-a86a-762cf635106f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d17488e-061c-4a91-a86a-762cf635106f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d17488e-061c-4a91-a86a-762cf635106f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d17488e-061c-4a91-a86a-762cf635106f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "yB8I5WlRSk_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precisao = accuracy_score(classe_teste, previssoes)\n",
        "precisao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnNyyGDCS7sr",
        "outputId": "ec73070e-631e-4ef2-9841-d733d3c2e089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8881118881118881"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matriz = confusion_matrix(classe_teste, previssoes)\n",
        "matriz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoJjdl23TNWJ",
        "outputId": "7cfd0def-fe49-47f8-fcf0-286be08c32e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[51,  8],\n",
              "       [ 8, 76]])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = classificador.evaluate(previsores_teste, classe_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71EcroaOTjpx",
        "outputId": "bded2241-1d13-4b16-8587-4b71e6dc8aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4222 - binary_accuracy: 0.8881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mais camadas e parâmetros do otimizador**"
      ],
      "metadata": {
        "id": "pQ20IzqdT8ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = Sequential()"
      ],
      "metadata": {
        "id": "4NcwrVi6UrVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# previsores\n",
        "#units (quantos neurones farão parte da camada oculta (numero de entradas (30) + número de saída sendo zero ou um então vai ser (1) dividido por 2  = 15.5) )\n",
        "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))"
      ],
      "metadata": {
        "id": "fhgJATOmUxPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform'))"
      ],
      "metadata": {
        "id": "rIE5g-FfUALa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classificadores\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "Bu0oKdjoU5DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "MB_Xv7SvXWbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "otimizador = keras.optimizers.Adam(lr = 0.001, decay = 0.0001 ,clipvalue=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Er9HkFeWZPI",
        "outputId": "c59f06a3-2ef0-428d-90f3-e835bda8804d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics = ['binary_accuracy'])"
      ],
      "metadata": {
        "id": "zeq7jpJ_XnzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ybIsrxX0Du",
        "outputId": "5a90a6dc-6f98-42d4-af58-80aed542c65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 2ms/step - loss: 0.7819 - binary_accuracy: 0.5892\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5241 - binary_accuracy: 0.7277\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4628 - binary_accuracy: 0.7911\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4501 - binary_accuracy: 0.8052\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4597 - binary_accuracy: 0.8075\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4119 - binary_accuracy: 0.8263\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4434 - binary_accuracy: 0.8239\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4439 - binary_accuracy: 0.8451\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4492 - binary_accuracy: 0.8404\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4748 - binary_accuracy: 0.8427\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4205 - binary_accuracy: 0.8451\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4951 - binary_accuracy: 0.8427\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3874 - binary_accuracy: 0.8474\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4024 - binary_accuracy: 0.8474\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4182 - binary_accuracy: 0.8545\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4500 - binary_accuracy: 0.8568\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5347 - binary_accuracy: 0.8263\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4593 - binary_accuracy: 0.8357\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5283 - binary_accuracy: 0.7981\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4703 - binary_accuracy: 0.8404\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4645 - binary_accuracy: 0.8380\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5100 - binary_accuracy: 0.8239\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4559 - binary_accuracy: 0.8380\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3609 - binary_accuracy: 0.8545\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3909 - binary_accuracy: 0.8615\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3716 - binary_accuracy: 0.8779\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3824 - binary_accuracy: 0.8685\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7170 - binary_accuracy: 0.8075\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.8638\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3970 - binary_accuracy: 0.8498\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3416 - binary_accuracy: 0.8685\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3857 - binary_accuracy: 0.8545\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3260 - binary_accuracy: 0.8897\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4354 - binary_accuracy: 0.8451\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4286 - binary_accuracy: 0.8357\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5346 - binary_accuracy: 0.8169\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4371 - binary_accuracy: 0.8685\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.8146\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5143 - binary_accuracy: 0.8404\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3822 - binary_accuracy: 0.8592\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4560 - binary_accuracy: 0.8451\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4104 - binary_accuracy: 0.8709\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4374 - binary_accuracy: 0.8638\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4472 - binary_accuracy: 0.8615\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6598 - binary_accuracy: 0.7887\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.2830 - binary_accuracy: 0.7277\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.8239\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5809 - binary_accuracy: 0.8404\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5862 - binary_accuracy: 0.8122\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.7958\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5585 - binary_accuracy: 0.8028\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5808 - binary_accuracy: 0.8075\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.8357\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5256 - binary_accuracy: 0.8451\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7724 - binary_accuracy: 0.7887\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5444 - binary_accuracy: 0.8263\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8967 - binary_accuracy: 0.7911\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7865 - binary_accuracy: 0.8216\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8599 - binary_accuracy: 0.8310\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5507 - binary_accuracy: 0.8263\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5121 - binary_accuracy: 0.8568\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6625 - binary_accuracy: 0.8146\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.8005\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4937 - binary_accuracy: 0.8451\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4413 - binary_accuracy: 0.8779\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6421 - binary_accuracy: 0.8263\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4645 - binary_accuracy: 0.8427\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5149 - binary_accuracy: 0.8568\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6545 - binary_accuracy: 0.8592\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6807 - binary_accuracy: 0.8239\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8248 - binary_accuracy: 0.8169\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7352 - binary_accuracy: 0.8427\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4878 - binary_accuracy: 0.8451\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5238 - binary_accuracy: 0.8239\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4524 - binary_accuracy: 0.8380\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4637 - binary_accuracy: 0.8592\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5344 - binary_accuracy: 0.8521\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5741 - binary_accuracy: 0.8592\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5364 - binary_accuracy: 0.8474\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7406 - binary_accuracy: 0.8286\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4644 - binary_accuracy: 0.8498\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5109 - binary_accuracy: 0.8615\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4572 - binary_accuracy: 0.8662\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4260 - binary_accuracy: 0.8568\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5744 - binary_accuracy: 0.8451\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4312 - binary_accuracy: 0.8592\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4420 - binary_accuracy: 0.8638\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5850 - binary_accuracy: 0.8286\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4789 - binary_accuracy: 0.8568\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5060 - binary_accuracy: 0.8427\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5334 - binary_accuracy: 0.8474\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5470 - binary_accuracy: 0.8521\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6584 - binary_accuracy: 0.8263\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5375 - binary_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8690 - binary_accuracy: 0.7864\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5144 - binary_accuracy: 0.8592\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4823 - binary_accuracy: 0.8474\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5063 - binary_accuracy: 0.8474\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5056 - binary_accuracy: 0.8615\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5347 - binary_accuracy: 0.8568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69685a3f50>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualização dos pesos**"
      ],
      "metadata": {
        "id": "vm9sA1UCYBdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pesos0 = classificador.layers[0].get_weights()\n",
        "pesos0"
      ],
      "metadata": {
        "id": "V0UlvaSAYErP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pesos1 = classificador.layers[1].get_weights()\n",
        "pesos1"
      ],
      "metadata": {
        "id": "WGPzYwr6YXpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pesos2 = classificador.layers[2].get_weights()\n",
        "pesos2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9rOtT7MYz_l",
        "outputId": "3dbfbbaf-690e-466b-dd09-2ce18f8febd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.32727903],\n",
              "        [-0.38133717],\n",
              "        [ 0.17431763],\n",
              "        [-0.47592485],\n",
              "        [-0.6071123 ],\n",
              "        [-0.42656794],\n",
              "        [ 0.15245871],\n",
              "        [-0.70380396],\n",
              "        [ 0.32262236],\n",
              "        [ 0.10869604],\n",
              "        [-0.39022255],\n",
              "        [ 0.2431184 ],\n",
              "        [-0.05324029],\n",
              "        [-0.5318647 ],\n",
              "        [ 0.16571994],\n",
              "        [ 0.26955697]], dtype=float32), array([0.24473685], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validação cruzada**"
      ],
      "metadata": {
        "id": "yOlMmAdkY6cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "jJiL1x_dbgSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "o2qyVvhsbuqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "s37q5gkaZD4b",
        "outputId": "53e28535-591e-472e-d1e8-c79dee81d308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c92cb377-b2ea-43d7-abfa-7740bd68a428\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c92cb377-b2ea-43d7-abfa-7740bd68a428')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c92cb377-b2ea-43d7-abfa-7740bd68a428 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c92cb377-b2ea-43d7-abfa-7740bd68a428');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe = pd.read_csv('/content/saidas_breast.csv')\n",
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N-iVFeDpbbYu",
        "outputId": "0c4cf192-6aea-4e32-a3dc-f62cb6786baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f47721d-5cbd-4e12-96ea-ced38a7f307c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f47721d-5cbd-4e12-96ea-ced38a7f307c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f47721d-5cbd-4e12-96ea-ced38a7f307c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f47721d-5cbd-4e12-96ea-ced38a7f307c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def criarRede():\n",
        "  classificador = Sequential()\n",
        "  # previsores\n",
        "  #units (quantos neurones farão parte da camada oculta (numero de entradas (30) + número de saída sendo zero ou um então vai ser (1) dividido por 2  = 15.5) )\n",
        "  classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))\n",
        "  classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform'))\n",
        "  #classificadores\n",
        "  classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  otimizador = keras.optimizers.Adam(lr = 0.001, decay = 0.0001 ,clipvalue=0.5)\n",
        "  classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "\n",
        "  return classificador"
      ],
      "metadata": {
        "id": "IGDZupQ_b4g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = KerasClassifier(build_fn= criarRede, epochs= 100, batch_size = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHhpzrAOcy9A",
        "outputId": "849a71ba-76fc-440a-bb13-f5247193353c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(estimator = classificador, X = previsores, y = classe, cv = 10, scoring = 'accuracy')"
      ],
      "metadata": {
        "id": "gdNJKJInixrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGl6DRsOj_5E",
        "outputId": "c7947406-2c5d-4952-df43-1200406e8154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.77192982, 0.78947368, 0.92982456, 0.68421053, 0.9122807 ,\n",
              "       0.8245614 , 0.85964912, 0.77192982, 0.64912281, 0.67857143])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBOYqZEykJsO",
        "outputId": "3e396ee3-5823-4b5c-b410-2115f1d277d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7871553884711779"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desvio_padrao = resultados.std()\n",
        "desvio_padrao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-UJt269kXnf",
        "outputId": "be14c773-77a2-46bb-b38e-4a26fb959fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09196494605592775"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overfitting e underfitting**\n",
        "\n",
        "**Underfitting***\n",
        "* Resultados ruins na base de treinamento\n",
        "**Overfitting**\n",
        "* Resultados bons na base de treinamento\n",
        "* Resultados ruins na base de teste\n",
        "* Muito específico\n",
        "* Memorização\n",
        "* Erros na variação de novas instâncias"
      ],
      "metadata": {
        "id": "GGAB5CZ_kn3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overfitting e dropout**"
      ],
      "metadata": {
        "id": "dSgXFkLimaZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "9P0nF4tWm_vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def criarRede():\n",
        "  classificador = Sequential()\n",
        "  # previsores\n",
        "  #units (quantos neurones farão parte da camada oculta (numero de entradas (30) + número de saída sendo zero ou um então vai ser (1) dividido por 2  = 15.5) )\n",
        "  classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))\n",
        "  classificador.add(Dropout(0.2))\n",
        "  classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer= 'random_uniform'))\n",
        "  classificador.add(Dropout(0.2))\n",
        "  #classificadores\n",
        "  classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  otimizador = keras.optimizers.Adam(lr = 0.001, decay = 0.0001 ,clipvalue=0.5)\n",
        "  classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "\n",
        "  return classificador"
      ],
      "metadata": {
        "id": "d96e4XK2mgZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = KerasClassifier(build_fn= criarRede, epochs= 100, batch_size = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu5gnfVXnXts",
        "outputId": "e5b5d94f-f980-46f1-bd9a-22a70cc391f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(estimator = classificador, X = previsores, y = classe, cv = 10, scoring = 'accuracy')\n",
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03LOiTbRnaHx",
        "outputId": "9128331d-fef6-4c37-d7b0-f17b4ab55fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 3ms/step - loss: 1.2810 - binary_accuracy: 0.5293\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6377 - binary_accuracy: 0.6738\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5592 - binary_accuracy: 0.7031\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.6404 - binary_accuracy: 0.6797\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6836\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6895\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5886 - binary_accuracy: 0.7051\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.7148\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5572 - binary_accuracy: 0.7598\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5530 - binary_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5423 - binary_accuracy: 0.7520\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5634 - binary_accuracy: 0.7812\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5596 - binary_accuracy: 0.7422\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5776 - binary_accuracy: 0.7480\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5032 - binary_accuracy: 0.7949\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5565 - binary_accuracy: 0.7812\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5501 - binary_accuracy: 0.7539\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5812 - binary_accuracy: 0.7715\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4963 - binary_accuracy: 0.8047\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4750 - binary_accuracy: 0.7773\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5092 - binary_accuracy: 0.7949\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4987 - binary_accuracy: 0.8066\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5178 - binary_accuracy: 0.7852\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5390 - binary_accuracy: 0.7773\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4745 - binary_accuracy: 0.8066\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4268 - binary_accuracy: 0.8262\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4666 - binary_accuracy: 0.8379\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4193 - binary_accuracy: 0.8320\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4723 - binary_accuracy: 0.8320\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4726 - binary_accuracy: 0.8574\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8128 - binary_accuracy: 0.8203\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4819 - binary_accuracy: 0.8242\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5756 - binary_accuracy: 0.8184\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4288 - binary_accuracy: 0.8340\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4103 - binary_accuracy: 0.8086\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7743 - binary_accuracy: 0.8184\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5699 - binary_accuracy: 0.8281\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5575 - binary_accuracy: 0.8691\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9367 - binary_accuracy: 0.8652\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5840 - binary_accuracy: 0.8320\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4356 - binary_accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.8438\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4390 - binary_accuracy: 0.8301\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4390 - binary_accuracy: 0.8477\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.8496\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6519 - binary_accuracy: 0.8594\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3932 - binary_accuracy: 0.8770\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9571 - binary_accuracy: 0.8730\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5897 - binary_accuracy: 0.8359\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4206 - binary_accuracy: 0.8633\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1978 - binary_accuracy: 0.8555\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7802 - binary_accuracy: 0.8633\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9700 - binary_accuracy: 0.8652\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8426 - binary_accuracy: 0.8770\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4115 - binary_accuracy: 0.8672\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5594 - binary_accuracy: 0.8730\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6622 - binary_accuracy: 0.8691\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8768 - binary_accuracy: 0.8457\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.1531 - binary_accuracy: 0.8887\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.9818 - binary_accuracy: 0.8555\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.8385 - binary_accuracy: 0.8535\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.0974 - binary_accuracy: 0.8770\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6243 - binary_accuracy: 0.8789\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.0309 - binary_accuracy: 0.8672\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6692 - binary_accuracy: 0.8652\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0548 - binary_accuracy: 0.8516\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6087 - binary_accuracy: 0.8516\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5829 - binary_accuracy: 0.8555\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8124 - binary_accuracy: 0.8828\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6811 - binary_accuracy: 0.8691\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7802 - binary_accuracy: 0.8809\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.8691\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2300 - binary_accuracy: 0.8594\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.8652\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6187 - binary_accuracy: 0.8691\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6485 - binary_accuracy: 0.8770\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7635 - binary_accuracy: 0.8555\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6732 - binary_accuracy: 0.8574\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.6534 - binary_accuracy: 0.8652\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7542 - binary_accuracy: 0.8770\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8355 - binary_accuracy: 0.8594\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7696 - binary_accuracy: 0.8711\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2595 - binary_accuracy: 0.8652\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0023 - binary_accuracy: 0.8691\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4873 - binary_accuracy: 0.8691\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4951 - binary_accuracy: 0.8613\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8453 - binary_accuracy: 0.8848\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4371 - binary_accuracy: 0.8594\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6977 - binary_accuracy: 0.8945\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.3324 - binary_accuracy: 0.8711\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7568 - binary_accuracy: 0.8691\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5322 - binary_accuracy: 0.8906\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.9737 - binary_accuracy: 0.8633\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1477 - binary_accuracy: 0.8711\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8544 - binary_accuracy: 0.8809\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.1599 - binary_accuracy: 0.8789\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8080 - binary_accuracy: 0.8613\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.2776 - binary_accuracy: 0.8711\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.3136 - binary_accuracy: 0.8438\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5109 - binary_accuracy: 0.8887\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.7537 - binary_accuracy: 0.5840\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7626 - binary_accuracy: 0.6348\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6699\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6615 - binary_accuracy: 0.7031\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6973\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.7148\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6875\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7183 - binary_accuracy: 0.7207\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6907 - binary_accuracy: 0.7109\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5416 - binary_accuracy: 0.7441\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6870 - binary_accuracy: 0.7305\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6873 - binary_accuracy: 0.7598\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6096 - binary_accuracy: 0.7441\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6077 - binary_accuracy: 0.7617\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6844 - binary_accuracy: 0.7617\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6965 - binary_accuracy: 0.7695\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5866 - binary_accuracy: 0.7852\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5228 - binary_accuracy: 0.7930\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2223 - binary_accuracy: 0.7754\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7786 - binary_accuracy: 0.7734\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6809 - binary_accuracy: 0.8125\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9233 - binary_accuracy: 0.8164\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3862 - binary_accuracy: 0.8008\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7635 - binary_accuracy: 0.8145\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9251 - binary_accuracy: 0.8242\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4215 - binary_accuracy: 0.8125\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6733 - binary_accuracy: 0.8359\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4218 - binary_accuracy: 0.8418\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4919 - binary_accuracy: 0.8242\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4910 - binary_accuracy: 0.8281\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9896 - binary_accuracy: 0.8027\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2778 - binary_accuracy: 0.8320\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8878 - binary_accuracy: 0.8457\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0153 - binary_accuracy: 0.8105\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8104 - binary_accuracy: 0.8301\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0732 - binary_accuracy: 0.8438\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1246 - binary_accuracy: 0.8145\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7422 - binary_accuracy: 0.8301\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4622 - binary_accuracy: 0.8340\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8972 - binary_accuracy: 0.8418\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4931 - binary_accuracy: 0.8125\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7155 - binary_accuracy: 0.8574\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9385 - binary_accuracy: 0.8418\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9439 - binary_accuracy: 0.8184\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6590 - binary_accuracy: 0.8223\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5352 - binary_accuracy: 0.8359\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9115 - binary_accuracy: 0.8184\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.5088 - binary_accuracy: 0.8086\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4563 - binary_accuracy: 0.8008\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0028 - binary_accuracy: 0.8594\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.3488 - binary_accuracy: 0.8145\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.6894 - binary_accuracy: 0.8242\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8582 - binary_accuracy: 0.8574\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5103 - binary_accuracy: 0.8340\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8293 - binary_accuracy: 0.8320\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5228 - binary_accuracy: 0.8457\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8137 - binary_accuracy: 0.8438\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6746 - binary_accuracy: 0.8320\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.6793 - binary_accuracy: 0.8555\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3498 - binary_accuracy: 0.8379\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3226 - binary_accuracy: 0.8281\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6915 - binary_accuracy: 0.8477\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8982 - binary_accuracy: 0.8652\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7733 - binary_accuracy: 0.8438\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.8457\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7951 - binary_accuracy: 0.8477\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 4.1961 - binary_accuracy: 0.8242\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.7860 - binary_accuracy: 0.8418\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.8360 - binary_accuracy: 0.8555\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.9727 - binary_accuracy: 0.8516\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0072 - binary_accuracy: 0.8320\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9376 - binary_accuracy: 0.8164\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5130 - binary_accuracy: 0.8672\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3524 - binary_accuracy: 0.8496\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1763 - binary_accuracy: 0.8574\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5725 - binary_accuracy: 0.8203\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8730 - binary_accuracy: 0.8262\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6094 - binary_accuracy: 0.8359\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0320 - binary_accuracy: 0.8379\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9017 - binary_accuracy: 0.8691\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8979 - binary_accuracy: 0.8379\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5814 - binary_accuracy: 0.8320\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2387 - binary_accuracy: 0.8555\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6649 - binary_accuracy: 0.8613\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0600 - binary_accuracy: 0.8398\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5466 - binary_accuracy: 0.8535\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0249 - binary_accuracy: 0.8379\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4133 - binary_accuracy: 0.8477\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1601 - binary_accuracy: 0.8438\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4825 - binary_accuracy: 0.8379\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8672 - binary_accuracy: 0.8555\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7055 - binary_accuracy: 0.8359\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4595 - binary_accuracy: 0.8652\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8014 - binary_accuracy: 0.8438\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4533 - binary_accuracy: 0.8867\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4160 - binary_accuracy: 0.8672\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8512 - binary_accuracy: 0.8457\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.8477\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4343 - binary_accuracy: 0.8691\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4566 - binary_accuracy: 0.8574\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.5294 - binary_accuracy: 0.5762\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6270\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5773 - binary_accuracy: 0.6504\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5581 - binary_accuracy: 0.7129\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5362 - binary_accuracy: 0.7012\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5354 - binary_accuracy: 0.7012\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5328 - binary_accuracy: 0.7402\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5009 - binary_accuracy: 0.7305\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4561 - binary_accuracy: 0.7812\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5119 - binary_accuracy: 0.7578\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4783 - binary_accuracy: 0.7734\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4315 - binary_accuracy: 0.7910\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4935 - binary_accuracy: 0.7520\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4608 - binary_accuracy: 0.7891\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5093 - binary_accuracy: 0.7734\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4818 - binary_accuracy: 0.7891\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4523 - binary_accuracy: 0.8086\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5167 - binary_accuracy: 0.7891\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4543 - binary_accuracy: 0.8086\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4703 - binary_accuracy: 0.7793\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4430 - binary_accuracy: 0.7988\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4902 - binary_accuracy: 0.7891\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4653 - binary_accuracy: 0.8242\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4234 - binary_accuracy: 0.8242\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4630 - binary_accuracy: 0.8125\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4403 - binary_accuracy: 0.8145\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4651 - binary_accuracy: 0.8262\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4321 - binary_accuracy: 0.8438\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4231 - binary_accuracy: 0.8125\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4231 - binary_accuracy: 0.8379\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4822 - binary_accuracy: 0.8320\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4104 - binary_accuracy: 0.8477\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3940 - binary_accuracy: 0.8340\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4398 - binary_accuracy: 0.8105\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4164 - binary_accuracy: 0.8398\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - binary_accuracy: 0.8555\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5682 - binary_accuracy: 0.8340\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4717 - binary_accuracy: 0.8301\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4309 - binary_accuracy: 0.8379\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4964 - binary_accuracy: 0.8594\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3961 - binary_accuracy: 0.8496\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4065 - binary_accuracy: 0.8535\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.8496\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4070 - binary_accuracy: 0.8496\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4351 - binary_accuracy: 0.8496\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5643 - binary_accuracy: 0.8398\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5833 - binary_accuracy: 0.8438\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8083 - binary_accuracy: 0.8242\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4117 - binary_accuracy: 0.8457\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4132 - binary_accuracy: 0.8281\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5838 - binary_accuracy: 0.8730\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5538 - binary_accuracy: 0.8223\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4325 - binary_accuracy: 0.8457\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4134 - binary_accuracy: 0.8477\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6224 - binary_accuracy: 0.8359\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5032 - binary_accuracy: 0.8184\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5577 - binary_accuracy: 0.8203\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4773 - binary_accuracy: 0.8535\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1087 - binary_accuracy: 0.8281\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4704 - binary_accuracy: 0.8320\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7813 - binary_accuracy: 0.8359\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4457 - binary_accuracy: 0.8379\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4180 - binary_accuracy: 0.8418\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5048 - binary_accuracy: 0.8418\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6369 - binary_accuracy: 0.8535\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - binary_accuracy: 0.8438\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0609 - binary_accuracy: 0.8301\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3941 - binary_accuracy: 0.8320\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7800 - binary_accuracy: 0.8496\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5108 - binary_accuracy: 0.8320\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6803 - binary_accuracy: 0.8555\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3766 - binary_accuracy: 0.8672\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4186 - binary_accuracy: 0.8789\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7626 - binary_accuracy: 0.8203\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4240 - binary_accuracy: 0.8594\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8198 - binary_accuracy: 0.8594\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7350 - binary_accuracy: 0.8613\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4273 - binary_accuracy: 0.8379\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4535 - binary_accuracy: 0.8281\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - binary_accuracy: 0.8555\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5829 - binary_accuracy: 0.8359\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6147 - binary_accuracy: 0.8301\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4097 - binary_accuracy: 0.8594\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6364 - binary_accuracy: 0.8496\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4097 - binary_accuracy: 0.8594\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6940 - binary_accuracy: 0.8672\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5628 - binary_accuracy: 0.8418\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4997 - binary_accuracy: 0.8535\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - binary_accuracy: 0.8652\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0480 - binary_accuracy: 0.8359\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5728 - binary_accuracy: 0.8438\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3769 - binary_accuracy: 0.8535\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3647 - binary_accuracy: 0.8535\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5018 - binary_accuracy: 0.8633\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6294 - binary_accuracy: 0.8555\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - binary_accuracy: 0.8652\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4283 - binary_accuracy: 0.8477\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7463 - binary_accuracy: 0.8535\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7989 - binary_accuracy: 0.8457\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 2.2282 - binary_accuracy: 0.5293\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6328\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5543 - binary_accuracy: 0.6719\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5300 - binary_accuracy: 0.7090\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5415 - binary_accuracy: 0.7070\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4992 - binary_accuracy: 0.7617\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4846 - binary_accuracy: 0.7734\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5112 - binary_accuracy: 0.7695\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5112 - binary_accuracy: 0.7812\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5094 - binary_accuracy: 0.7988\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5369 - binary_accuracy: 0.8086\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4901 - binary_accuracy: 0.8223\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - binary_accuracy: 0.8379\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4582 - binary_accuracy: 0.8301\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5539 - binary_accuracy: 0.8027\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5879 - binary_accuracy: 0.8223\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4664 - binary_accuracy: 0.8281\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4974 - binary_accuracy: 0.8281\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5553 - binary_accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5060 - binary_accuracy: 0.8516\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4394 - binary_accuracy: 0.8320\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4826 - binary_accuracy: 0.8379\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5489 - binary_accuracy: 0.8359\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8454 - binary_accuracy: 0.8613\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5802 - binary_accuracy: 0.8535\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6186 - binary_accuracy: 0.8535\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5879 - binary_accuracy: 0.8457\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5305 - binary_accuracy: 0.8711\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7237 - binary_accuracy: 0.8613\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4085 - binary_accuracy: 0.8711\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6753 - binary_accuracy: 0.8652\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7034 - binary_accuracy: 0.8555\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6447 - binary_accuracy: 0.8633\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5369 - binary_accuracy: 0.8770\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8965\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4784 - binary_accuracy: 0.8477\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3517 - binary_accuracy: 0.8711\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5168 - binary_accuracy: 0.8906\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5048 - binary_accuracy: 0.8711\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3441 - binary_accuracy: 0.8594\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5363 - binary_accuracy: 0.8809\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5567 - binary_accuracy: 0.8848\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8080 - binary_accuracy: 0.8828\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6623 - binary_accuracy: 0.9004\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6954 - binary_accuracy: 0.8750\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6386 - binary_accuracy: 0.8828\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7757 - binary_accuracy: 0.8770\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4337 - binary_accuracy: 0.8926\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6930 - binary_accuracy: 0.8965\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9385 - binary_accuracy: 0.8887\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5074 - binary_accuracy: 0.9160\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3528 - binary_accuracy: 0.8965\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7780 - binary_accuracy: 0.8730\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3187 - binary_accuracy: 0.8984\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5273 - binary_accuracy: 0.8906\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9290 - binary_accuracy: 0.8750\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8848\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4643 - binary_accuracy: 0.8848\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4989 - binary_accuracy: 0.9023\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4289 - binary_accuracy: 0.8945\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.8848\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2974 - binary_accuracy: 0.8809\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4222 - binary_accuracy: 0.8906\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3416 - binary_accuracy: 0.8984\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5761 - binary_accuracy: 0.8984\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2886 - binary_accuracy: 0.9121\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9923 - binary_accuracy: 0.9043\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6994 - binary_accuracy: 0.9023\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8285 - binary_accuracy: 0.8848\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6787 - binary_accuracy: 0.8945\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3886 - binary_accuracy: 0.9082\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4571 - binary_accuracy: 0.9023\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7189 - binary_accuracy: 0.9043\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6328 - binary_accuracy: 0.8945\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3043 - binary_accuracy: 0.9160\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3208 - binary_accuracy: 0.9121\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4478 - binary_accuracy: 0.9141\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2959 - binary_accuracy: 0.9121\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3806 - binary_accuracy: 0.9121\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6346 - binary_accuracy: 0.9082\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3945 - binary_accuracy: 0.9082\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4552 - binary_accuracy: 0.9062\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7669 - binary_accuracy: 0.9023\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4060 - binary_accuracy: 0.9180\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4327 - binary_accuracy: 0.9023\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.3162 - binary_accuracy: 0.9141\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4191 - binary_accuracy: 0.9004\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3212 - binary_accuracy: 0.9180\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4642 - binary_accuracy: 0.9043\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8071 - binary_accuracy: 0.9121\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5264 - binary_accuracy: 0.8906\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3071 - binary_accuracy: 0.9043\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2678 - binary_accuracy: 0.9258\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4127 - binary_accuracy: 0.9004\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3425 - binary_accuracy: 0.9121\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2977 - binary_accuracy: 0.9102\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3120 - binary_accuracy: 0.9102\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4969 - binary_accuracy: 0.9023\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3004 - binary_accuracy: 0.9258\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5099 - binary_accuracy: 0.9102\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.1125 - binary_accuracy: 0.5938\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6957 - binary_accuracy: 0.6914\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6831 - binary_accuracy: 0.6973\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6665 - binary_accuracy: 0.7051\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5521 - binary_accuracy: 0.7363\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5408 - binary_accuracy: 0.7285\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6510 - binary_accuracy: 0.6758\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5745 - binary_accuracy: 0.7188\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5464 - binary_accuracy: 0.7480\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5687 - binary_accuracy: 0.7422\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5791 - binary_accuracy: 0.7305\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5094 - binary_accuracy: 0.7383\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6436 - binary_accuracy: 0.7734\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5040 - binary_accuracy: 0.7910\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5559 - binary_accuracy: 0.7676\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5351 - binary_accuracy: 0.7793\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7043 - binary_accuracy: 0.7422\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5453 - binary_accuracy: 0.7812\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6130 - binary_accuracy: 0.7832\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5386 - binary_accuracy: 0.7949\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5099 - binary_accuracy: 0.8145\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5290 - binary_accuracy: 0.7910\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.7891\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.7871\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4727 - binary_accuracy: 0.8125\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5801 - binary_accuracy: 0.7871\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8533 - binary_accuracy: 0.7930\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5015 - binary_accuracy: 0.8164\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4916 - binary_accuracy: 0.8125\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5302 - binary_accuracy: 0.8047\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7408 - binary_accuracy: 0.7910\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7725 - binary_accuracy: 0.7969\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8696 - binary_accuracy: 0.8105\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8877 - binary_accuracy: 0.8145\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7080 - binary_accuracy: 0.8438\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.8340\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.8047\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4064 - binary_accuracy: 0.8418\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5476 - binary_accuracy: 0.8203\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6926 - binary_accuracy: 0.8164\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1582 - binary_accuracy: 0.8086\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5271 - binary_accuracy: 0.8145\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.8105\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4040 - binary_accuracy: 0.8223\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9327 - binary_accuracy: 0.8164\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5501 - binary_accuracy: 0.8477\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.8281\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6839 - binary_accuracy: 0.8477\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6864 - binary_accuracy: 0.8105\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.8125\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6438 - binary_accuracy: 0.8359\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5317 - binary_accuracy: 0.8438\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9383 - binary_accuracy: 0.8496\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5146 - binary_accuracy: 0.8418\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7137 - binary_accuracy: 0.8301\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7180 - binary_accuracy: 0.8457\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7001 - binary_accuracy: 0.8613\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6965 - binary_accuracy: 0.8281\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0602 - binary_accuracy: 0.8301\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7303 - binary_accuracy: 0.8320\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.8438\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.8398\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5588 - binary_accuracy: 0.8223\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4632 - binary_accuracy: 0.8379\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4590 - binary_accuracy: 0.8418\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4216 - binary_accuracy: 0.8398\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7259 - binary_accuracy: 0.8242\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5480 - binary_accuracy: 0.8379\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6477 - binary_accuracy: 0.8750\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5790 - binary_accuracy: 0.8477\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4929 - binary_accuracy: 0.8203\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5761 - binary_accuracy: 0.8438\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4178 - binary_accuracy: 0.8438\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.8301\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5032 - binary_accuracy: 0.8223\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5387 - binary_accuracy: 0.8223\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5490 - binary_accuracy: 0.8398\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7652 - binary_accuracy: 0.8457\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4985 - binary_accuracy: 0.8281\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9809 - binary_accuracy: 0.8457\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8567 - binary_accuracy: 0.8438\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8124 - binary_accuracy: 0.8574\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7496 - binary_accuracy: 0.8398\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4146 - binary_accuracy: 0.8516\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9636 - binary_accuracy: 0.8242\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5269 - binary_accuracy: 0.8359\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9090 - binary_accuracy: 0.8340\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4706 - binary_accuracy: 0.8457\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9538 - binary_accuracy: 0.8398\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5214 - binary_accuracy: 0.8359\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5161 - binary_accuracy: 0.8730\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.8438\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5188 - binary_accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4770 - binary_accuracy: 0.8457\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5531 - binary_accuracy: 0.8535\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7788 - binary_accuracy: 0.8398\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0283 - binary_accuracy: 0.8379\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7762 - binary_accuracy: 0.8574\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8953 - binary_accuracy: 0.8574\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.9274 - binary_accuracy: 0.8262\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 0.9800 - binary_accuracy: 0.5801\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6715 - binary_accuracy: 0.6348\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6387\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5869 - binary_accuracy: 0.6738\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6602\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6875\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6603 - binary_accuracy: 0.6699\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6816\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5774 - binary_accuracy: 0.7227\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6726 - binary_accuracy: 0.7012\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.7168\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.7148\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6320 - binary_accuracy: 0.7402\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.7461\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5709 - binary_accuracy: 0.7031\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5558 - binary_accuracy: 0.7539\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5714 - binary_accuracy: 0.7324\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5328 - binary_accuracy: 0.7559\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5350 - binary_accuracy: 0.7930\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5153 - binary_accuracy: 0.7852\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5476 - binary_accuracy: 0.7852\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6526 - binary_accuracy: 0.7520\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5001 - binary_accuracy: 0.7715\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4852 - binary_accuracy: 0.8047\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4659 - binary_accuracy: 0.7832\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5202 - binary_accuracy: 0.7891\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4706 - binary_accuracy: 0.8047\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5046 - binary_accuracy: 0.8125\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4975 - binary_accuracy: 0.8086\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4341 - binary_accuracy: 0.8105\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4562 - binary_accuracy: 0.8008\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4022 - binary_accuracy: 0.8340\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4378 - binary_accuracy: 0.8125\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4935 - binary_accuracy: 0.8105\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4370 - binary_accuracy: 0.8164\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4536 - binary_accuracy: 0.8340\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4074 - binary_accuracy: 0.8164\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4230 - binary_accuracy: 0.8145\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4077 - binary_accuracy: 0.8359\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4050 - binary_accuracy: 0.8340\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4257 - binary_accuracy: 0.8086\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4066 - binary_accuracy: 0.8359\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3775 - binary_accuracy: 0.8359\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3942 - binary_accuracy: 0.8516\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3992 - binary_accuracy: 0.8262\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4209 - binary_accuracy: 0.8145\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3864 - binary_accuracy: 0.8418\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - binary_accuracy: 0.8496\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.8223\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4200 - binary_accuracy: 0.8516\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3897 - binary_accuracy: 0.8301\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3938 - binary_accuracy: 0.8281\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3517 - binary_accuracy: 0.8672\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3799 - binary_accuracy: 0.8379\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4364 - binary_accuracy: 0.8379\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3988 - binary_accuracy: 0.8398\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3678 - binary_accuracy: 0.8535\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4069 - binary_accuracy: 0.8223\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3669 - binary_accuracy: 0.8379\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3813 - binary_accuracy: 0.8477\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3951 - binary_accuracy: 0.8281\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8594\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8711\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3617 - binary_accuracy: 0.8496\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.8301\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3745 - binary_accuracy: 0.8516\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3599 - binary_accuracy: 0.8672\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - binary_accuracy: 0.8398\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3620 - binary_accuracy: 0.8652\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3910 - binary_accuracy: 0.8496\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3455 - binary_accuracy: 0.8691\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3660 - binary_accuracy: 0.8652\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3958 - binary_accuracy: 0.8516\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - binary_accuracy: 0.8594\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4056 - binary_accuracy: 0.8340\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4118 - binary_accuracy: 0.8398\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8379\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3560 - binary_accuracy: 0.8730\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4216 - binary_accuracy: 0.8320\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3612 - binary_accuracy: 0.8574\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4110 - binary_accuracy: 0.8594\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3680 - binary_accuracy: 0.8672\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3431 - binary_accuracy: 0.8809\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4156 - binary_accuracy: 0.8340\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4008 - binary_accuracy: 0.8398\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3887 - binary_accuracy: 0.8711\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4232 - binary_accuracy: 0.8457\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - binary_accuracy: 0.8574\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3935 - binary_accuracy: 0.8359\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3973 - binary_accuracy: 0.8457\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4146 - binary_accuracy: 0.8477\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3806 - binary_accuracy: 0.8574\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3769 - binary_accuracy: 0.8594\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3775 - binary_accuracy: 0.8496\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4013 - binary_accuracy: 0.8477\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3896 - binary_accuracy: 0.8438\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - binary_accuracy: 0.8535\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3990 - binary_accuracy: 0.8359\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3694 - binary_accuracy: 0.8652\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4263 - binary_accuracy: 0.8496\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.4268 - binary_accuracy: 0.5957\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8528 - binary_accuracy: 0.6426\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6532 - binary_accuracy: 0.7051\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6934\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.7207\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6431 - binary_accuracy: 0.6895\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5645 - binary_accuracy: 0.7324\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5077 - binary_accuracy: 0.7324\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5714 - binary_accuracy: 0.7520\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5875 - binary_accuracy: 0.7441\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5470 - binary_accuracy: 0.7324\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.7773\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6707 - binary_accuracy: 0.7305\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7150 - binary_accuracy: 0.7344\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5410 - binary_accuracy: 0.7676\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5576 - binary_accuracy: 0.7461\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5170 - binary_accuracy: 0.7715\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6731 - binary_accuracy: 0.7539\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5271 - binary_accuracy: 0.7852\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.7852\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5204 - binary_accuracy: 0.7715\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.6988 - binary_accuracy: 0.7988\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5548 - binary_accuracy: 0.7852\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.6239 - binary_accuracy: 0.7480\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5237 - binary_accuracy: 0.7852\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4919 - binary_accuracy: 0.7988\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5307 - binary_accuracy: 0.7676\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4715 - binary_accuracy: 0.7910\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5689 - binary_accuracy: 0.8145\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.7871\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4850 - binary_accuracy: 0.7930\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5352 - binary_accuracy: 0.7949\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5554 - binary_accuracy: 0.7871\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5295 - binary_accuracy: 0.7812\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4997 - binary_accuracy: 0.8066\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5055 - binary_accuracy: 0.7910\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4783 - binary_accuracy: 0.8027\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.8027\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4272 - binary_accuracy: 0.8379\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5201 - binary_accuracy: 0.8164\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4218 - binary_accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5269 - binary_accuracy: 0.8340\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4321 - binary_accuracy: 0.8301\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5382 - binary_accuracy: 0.8223\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4158 - binary_accuracy: 0.8438\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5193 - binary_accuracy: 0.8066\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4652 - binary_accuracy: 0.8203\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4394 - binary_accuracy: 0.8320\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4053 - binary_accuracy: 0.8359\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4478 - binary_accuracy: 0.8301\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4819 - binary_accuracy: 0.8359\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6670 - binary_accuracy: 0.7988\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4569 - binary_accuracy: 0.8516\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4065 - binary_accuracy: 0.8262\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4295 - binary_accuracy: 0.8281\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4207 - binary_accuracy: 0.8418\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7187 - binary_accuracy: 0.8398\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4057 - binary_accuracy: 0.8594\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7620 - binary_accuracy: 0.8516\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7040 - binary_accuracy: 0.8359\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.8359\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7228 - binary_accuracy: 0.8516\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8034 - binary_accuracy: 0.8223\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8766 - binary_accuracy: 0.8320\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8513 - binary_accuracy: 0.8477\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.8594\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6884 - binary_accuracy: 0.8242\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.9939 - binary_accuracy: 0.8418\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8387 - binary_accuracy: 0.8574\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8717 - binary_accuracy: 0.8516\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4998 - binary_accuracy: 0.8145\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6625 - binary_accuracy: 0.8535\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.9518 - binary_accuracy: 0.8320\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5481 - binary_accuracy: 0.8262\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9423 - binary_accuracy: 0.8398\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5702 - binary_accuracy: 0.8301\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7678 - binary_accuracy: 0.8477\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6745 - binary_accuracy: 0.8203\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6384 - binary_accuracy: 0.8145\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5731 - binary_accuracy: 0.8496\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2031 - binary_accuracy: 0.8477\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3485 - binary_accuracy: 0.8262\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3445 - binary_accuracy: 0.8262\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0131 - binary_accuracy: 0.8105\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7970 - binary_accuracy: 0.8340\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7900 - binary_accuracy: 0.8457\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8674 - binary_accuracy: 0.8535\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7064 - binary_accuracy: 0.8359\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5597 - binary_accuracy: 0.8242\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.9314 - binary_accuracy: 0.8457\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3205 - binary_accuracy: 0.8262\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7199 - binary_accuracy: 0.8535\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7207 - binary_accuracy: 0.8496\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.8301\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7492 - binary_accuracy: 0.8262\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8367 - binary_accuracy: 0.8301\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7071 - binary_accuracy: 0.8281\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5834 - binary_accuracy: 0.8145\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6889 - binary_accuracy: 0.8281\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4838 - binary_accuracy: 0.8359\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.8890 - binary_accuracy: 0.5625\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6760 - binary_accuracy: 0.6133\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6510 - binary_accuracy: 0.6211\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6621\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5415 - binary_accuracy: 0.6855\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5872 - binary_accuracy: 0.6758\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5388 - binary_accuracy: 0.7227\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5728 - binary_accuracy: 0.7285\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4972 - binary_accuracy: 0.7715\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5328 - binary_accuracy: 0.7559\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5202 - binary_accuracy: 0.7539\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6023 - binary_accuracy: 0.7480\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5875 - binary_accuracy: 0.7715\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4972 - binary_accuracy: 0.7832\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5225 - binary_accuracy: 0.7891\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.7598\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5118 - binary_accuracy: 0.7871\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.7754\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4752 - binary_accuracy: 0.8145\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4427 - binary_accuracy: 0.8223\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4894 - binary_accuracy: 0.8027\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5404 - binary_accuracy: 0.7910\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4921 - binary_accuracy: 0.7988\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5092 - binary_accuracy: 0.7871\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5335 - binary_accuracy: 0.8105\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4781 - binary_accuracy: 0.8047\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4467 - binary_accuracy: 0.8301\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4177 - binary_accuracy: 0.8281\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4383 - binary_accuracy: 0.8320\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4136 - binary_accuracy: 0.8223\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4585 - binary_accuracy: 0.8164\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4339 - binary_accuracy: 0.8320\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4312 - binary_accuracy: 0.8340\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4454 - binary_accuracy: 0.8438\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4538 - binary_accuracy: 0.8359\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4330 - binary_accuracy: 0.8516\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3948 - binary_accuracy: 0.8574\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5187 - binary_accuracy: 0.8320\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4463 - binary_accuracy: 0.8691\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5010 - binary_accuracy: 0.8457\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4771 - binary_accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4426 - binary_accuracy: 0.8594\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3960 - binary_accuracy: 0.8652\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4372 - binary_accuracy: 0.8477\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4577 - binary_accuracy: 0.8516\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4704 - binary_accuracy: 0.8652\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4088 - binary_accuracy: 0.8672\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4034 - binary_accuracy: 0.8535\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4174 - binary_accuracy: 0.8535\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4993 - binary_accuracy: 0.8594\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5002 - binary_accuracy: 0.8613\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4173 - binary_accuracy: 0.8516\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - binary_accuracy: 0.8516\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6465 - binary_accuracy: 0.8457\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - binary_accuracy: 0.8809\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0128 - binary_accuracy: 0.8379\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8429 - binary_accuracy: 0.8398\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8974 - binary_accuracy: 0.8594\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6721 - binary_accuracy: 0.8691\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5106 - binary_accuracy: 0.8633\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.9336 - binary_accuracy: 0.8496\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.9799 - binary_accuracy: 0.8652\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.6319 - binary_accuracy: 0.8867\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.7134 - binary_accuracy: 0.8750\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7084 - binary_accuracy: 0.8652\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 1.0229 - binary_accuracy: 0.8320\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5771 - binary_accuracy: 0.8594\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6304 - binary_accuracy: 0.8789\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4176 - binary_accuracy: 0.8555\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.6781 - binary_accuracy: 0.8672\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.8210 - binary_accuracy: 0.8809\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.0574 - binary_accuracy: 0.8750\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5214 - binary_accuracy: 0.8770\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7074 - binary_accuracy: 0.8965\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7740 - binary_accuracy: 0.8789\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5511 - binary_accuracy: 0.8809\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8158 - binary_accuracy: 0.8633\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6377 - binary_accuracy: 0.8926\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4967 - binary_accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8099 - binary_accuracy: 0.8672\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4083 - binary_accuracy: 0.8652\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8937 - binary_accuracy: 0.8750\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4147 - binary_accuracy: 0.8672\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3880 - binary_accuracy: 0.9004\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4649 - binary_accuracy: 0.8848\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3839 - binary_accuracy: 0.8828\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5292 - binary_accuracy: 0.8926\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5456 - binary_accuracy: 0.8867\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.8828\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7366 - binary_accuracy: 0.8906\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5450 - binary_accuracy: 0.8945\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6426 - binary_accuracy: 0.8828\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9363 - binary_accuracy: 0.8809\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6612 - binary_accuracy: 0.8867\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7085 - binary_accuracy: 0.8750\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6473 - binary_accuracy: 0.8867\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3232 - binary_accuracy: 0.8984\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6870 - binary_accuracy: 0.8711\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8218 - binary_accuracy: 0.8926\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2874 - binary_accuracy: 0.8887\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.5400 - binary_accuracy: 0.5879\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6896 - binary_accuracy: 0.6562\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6582\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5817 - binary_accuracy: 0.6816\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5870 - binary_accuracy: 0.7090\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7109 - binary_accuracy: 0.6797\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5583 - binary_accuracy: 0.7109\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6855\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.7383\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5178 - binary_accuracy: 0.7188\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.7363\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5906 - binary_accuracy: 0.7383\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5707 - binary_accuracy: 0.7461\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.7578\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5316 - binary_accuracy: 0.7324\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5720 - binary_accuracy: 0.7168\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5588 - binary_accuracy: 0.7715\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5743 - binary_accuracy: 0.7656\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4693 - binary_accuracy: 0.7949\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4976 - binary_accuracy: 0.7832\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5273 - binary_accuracy: 0.7891\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4915 - binary_accuracy: 0.8125\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6367 - binary_accuracy: 0.7637\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4819 - binary_accuracy: 0.8086\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.7949\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4749 - binary_accuracy: 0.8125\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5260 - binary_accuracy: 0.7812\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4635 - binary_accuracy: 0.8145\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5064 - binary_accuracy: 0.7910\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5123 - binary_accuracy: 0.8086\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4355 - binary_accuracy: 0.8242\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5524 - binary_accuracy: 0.8047\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4439 - binary_accuracy: 0.8145\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4840 - binary_accuracy: 0.8105\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4831 - binary_accuracy: 0.8301\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4350 - binary_accuracy: 0.8301\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4529 - binary_accuracy: 0.8242\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4599 - binary_accuracy: 0.8340\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4366 - binary_accuracy: 0.8184\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5109 - binary_accuracy: 0.8145\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4825 - binary_accuracy: 0.8047\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4780 - binary_accuracy: 0.8105\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5181 - binary_accuracy: 0.8145\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4342 - binary_accuracy: 0.8516\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5151 - binary_accuracy: 0.8496\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4695 - binary_accuracy: 0.7988\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5012 - binary_accuracy: 0.8281\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4310 - binary_accuracy: 0.8223\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4812 - binary_accuracy: 0.8281\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5435 - binary_accuracy: 0.8184\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4835 - binary_accuracy: 0.8359\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4598 - binary_accuracy: 0.8320\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4957 - binary_accuracy: 0.8262\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3986 - binary_accuracy: 0.8496\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5882 - binary_accuracy: 0.8574\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4476 - binary_accuracy: 0.8379\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4078 - binary_accuracy: 0.8359\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5106 - binary_accuracy: 0.8320\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4600 - binary_accuracy: 0.8242\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4241 - binary_accuracy: 0.8301\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3897 - binary_accuracy: 0.8340\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4353 - binary_accuracy: 0.8398\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4426 - binary_accuracy: 0.8379\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3774 - binary_accuracy: 0.8574\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.8496\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4448 - binary_accuracy: 0.8418\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4174 - binary_accuracy: 0.8379\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4430 - binary_accuracy: 0.8398\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4722 - binary_accuracy: 0.8535\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - binary_accuracy: 0.8535\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3506 - binary_accuracy: 0.8730\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5078 - binary_accuracy: 0.8242\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4408 - binary_accuracy: 0.8418\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.8516\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3965 - binary_accuracy: 0.8457\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5006 - binary_accuracy: 0.8594\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4709 - binary_accuracy: 0.8457\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5026 - binary_accuracy: 0.8340\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4176 - binary_accuracy: 0.8379\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3961 - binary_accuracy: 0.8438\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5364 - binary_accuracy: 0.8613\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5042 - binary_accuracy: 0.8496\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4419 - binary_accuracy: 0.8613\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5111 - binary_accuracy: 0.8477\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4258 - binary_accuracy: 0.8613\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4412 - binary_accuracy: 0.8457\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4723 - binary_accuracy: 0.8672\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.8535\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4745 - binary_accuracy: 0.8770\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3697 - binary_accuracy: 0.8652\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4569 - binary_accuracy: 0.8652\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.8398\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4860 - binary_accuracy: 0.8457\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4959 - binary_accuracy: 0.8652\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4206 - binary_accuracy: 0.8574\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5581 - binary_accuracy: 0.8359\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4185 - binary_accuracy: 0.8574\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4143 - binary_accuracy: 0.8730\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4365 - binary_accuracy: 0.8633\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4419 - binary_accuracy: 0.8574\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 1.6003 - binary_accuracy: 0.6335\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8556 - binary_accuracy: 0.6686\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8239 - binary_accuracy: 0.6238\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7267 - binary_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6479 - binary_accuracy: 0.6803\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6807 - binary_accuracy: 0.7251\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7769 - binary_accuracy: 0.7018\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6670 - binary_accuracy: 0.7446\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6369 - binary_accuracy: 0.7057\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8283 - binary_accuracy: 0.6745\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5855 - binary_accuracy: 0.7505\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7175 - binary_accuracy: 0.7037\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6457 - binary_accuracy: 0.6940\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5875 - binary_accuracy: 0.7212\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6718 - binary_accuracy: 0.6920\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6920\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5675 - binary_accuracy: 0.7602\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5866 - binary_accuracy: 0.7349\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.7407\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5266 - binary_accuracy: 0.7680\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.7290\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.7290\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5848 - binary_accuracy: 0.7251\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5197 - binary_accuracy: 0.7466\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6687 - binary_accuracy: 0.7251\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6404 - binary_accuracy: 0.7368\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5926 - binary_accuracy: 0.7485\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5539 - binary_accuracy: 0.7505\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5063 - binary_accuracy: 0.7739\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5773 - binary_accuracy: 0.7602\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5915 - binary_accuracy: 0.7739\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5226 - binary_accuracy: 0.7622\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5683 - binary_accuracy: 0.7485\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5346 - binary_accuracy: 0.7661\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5060 - binary_accuracy: 0.7739\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4450 - binary_accuracy: 0.7875\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5634 - binary_accuracy: 0.7524\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5159 - binary_accuracy: 0.7778\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4905 - binary_accuracy: 0.8031\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5386 - binary_accuracy: 0.7836\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5523 - binary_accuracy: 0.7758\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.7739\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5087 - binary_accuracy: 0.7797\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5027 - binary_accuracy: 0.7661\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4662 - binary_accuracy: 0.8148\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4948 - binary_accuracy: 0.7797\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5039 - binary_accuracy: 0.7973\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6163 - binary_accuracy: 0.7856\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5317 - binary_accuracy: 0.8090\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5782 - binary_accuracy: 0.8012\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4928 - binary_accuracy: 0.8226\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5116 - binary_accuracy: 0.8129\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4657 - binary_accuracy: 0.8382\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5069 - binary_accuracy: 0.8265\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.8090\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4315 - binary_accuracy: 0.8207\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5300 - binary_accuracy: 0.8051\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - binary_accuracy: 0.8402\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4703 - binary_accuracy: 0.8402\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5525 - binary_accuracy: 0.8168\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5161 - binary_accuracy: 0.8207\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4676 - binary_accuracy: 0.8324\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5581 - binary_accuracy: 0.8265\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.8148\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5272 - binary_accuracy: 0.8382\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4479 - binary_accuracy: 0.8402\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6531 - binary_accuracy: 0.8168\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5546 - binary_accuracy: 0.8168\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5235 - binary_accuracy: 0.8226\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4892 - binary_accuracy: 0.8382\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5328 - binary_accuracy: 0.8441\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4508 - binary_accuracy: 0.8382\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6737 - binary_accuracy: 0.8109\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5170 - binary_accuracy: 0.8246\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4788 - binary_accuracy: 0.8285\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5115 - binary_accuracy: 0.8246\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5110 - binary_accuracy: 0.8558\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4485 - binary_accuracy: 0.8441\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4859 - binary_accuracy: 0.8382\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7414 - binary_accuracy: 0.8441\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6617 - binary_accuracy: 0.8343\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4758 - binary_accuracy: 0.8382\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5737 - binary_accuracy: 0.8226\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4449 - binary_accuracy: 0.8421\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6544 - binary_accuracy: 0.8109\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5757 - binary_accuracy: 0.8460\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3722 - binary_accuracy: 0.8441\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5538 - binary_accuracy: 0.8402\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4008 - binary_accuracy: 0.8519\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4468 - binary_accuracy: 0.8226\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4970 - binary_accuracy: 0.8343\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.8265\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5758 - binary_accuracy: 0.8363\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4669 - binary_accuracy: 0.8538\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4189 - binary_accuracy: 0.8402\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5652 - binary_accuracy: 0.8363\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4821 - binary_accuracy: 0.8596\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5474 - binary_accuracy: 0.8382\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4818 - binary_accuracy: 0.8402\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5716 - binary_accuracy: 0.8324\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78947368, 0.89473684, 0.89473684, 0.84210526, 0.92982456,\n",
              "       0.92982456, 0.87719298, 0.96491228, 0.85964912, 0.91071429])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LznGklCCndrh",
        "outputId": "1f4ccfc2-cf67-4e3b-882b-7bc77254069a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8893170426065163"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desvio_padrao = resultados.std()\n",
        "desvio_padrao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEWnIKbnfnX",
        "outputId": "328d153f-c8c2-44b1-f19c-dd8f0c76b308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.047684143361220364"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning (ajuste) dos parâmetros**"
      ],
      "metadata": {
        "id": "rIsJ1vh3n2C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "vr0j6hJgn6e9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JkX5Qersr_Sf",
        "outputId": "4bb43e68-f145-4e5f-ad5d-692b52c6ede5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d98374d-845c-4023-8652-0ddb8deb5dcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d98374d-845c-4023-8652-0ddb8deb5dcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d98374d-845c-4023-8652-0ddb8deb5dcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d98374d-845c-4023-8652-0ddb8deb5dcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe = pd.read_csv('/content/saidas_breast.csv')\n",
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JkqbewJrsCFV",
        "outputId": "65e85d5e-f0a5-4e15-a958-20232ea5cce6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-296d0099-3d93-4a12-afb3-70e3fa1f9ca4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-296d0099-3d93-4a12-afb3-70e3fa1f9ca4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-296d0099-3d93-4a12-afb3-70e3fa1f9ca4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-296d0099-3d93-4a12-afb3-70e3fa1f9ca4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def criarRede(optimizer, loss, kernel_initializer, activation, neurons):\n",
        "  classificador = Sequential()\n",
        "  # previsores\n",
        "  #units (quantos neurones farão parte da camada oculta (numero de entradas (30) + número de saída sendo zero ou um então vai ser (1) dividido por 2  = 15.5) )\n",
        "  classificador.add(Dense(units = neurons, activation = activation, kernel_initializer= kernel_initializer, input_dim = 30))\n",
        "  classificador.add(Dropout(0.2))\n",
        "  classificador.add(Dense(units = neurons, activation = activation, kernel_initializer= kernel_initializer))\n",
        "  classificador.add(Dropout(0.2))\n",
        "  #classificadores\n",
        "  classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  classificador.compile(optimizer=optimizer, loss= loss, metrics = ['binary_accuracy'])\n",
        "\n",
        "  return classificador"
      ],
      "metadata": {
        "id": "h4FSOG4psGcc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = KerasClassifier(build_fn= criarRede)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmSz9DR0tEn1",
        "outputId": "70a3a284-1bc6-4bf1-c41f-4eb59c12a406"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parametros = {'batch_size': [10, 30],\n",
        "              'epochs': [50, 100],\n",
        "              'optimizer': ['adam', 'sgd'],\n",
        "              'loss': ['binary_crossentropy', 'hinge'],\n",
        "              'kernel_initializer': ['random_uniform', 'normal'],\n",
        "              'activation': ['relu', 'tanh'],\n",
        "              'neurons' : [16, 8]}"
      ],
      "metadata": {
        "id": "_TwUcjIjvM8M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(estimator = classificador, param_grid= parametros, scoring = 'accuracy', cv = 5)"
      ],
      "metadata": {
        "id": "Pg7QIb0xwhov"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = grid_search.fit(previsores, classe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyt-jKtvw2NF",
        "outputId": "a10ecab3-d7ae-4ac1-a628-3b7d4d974ff9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "16/16 [==============================] - 1s 6ms/step - loss: 0.6746 - binary_accuracy: 0.5934\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6730 - binary_accuracy: 0.6022\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6606 - binary_accuracy: 0.6220\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6586 - binary_accuracy: 0.6330\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6506 - binary_accuracy: 0.6352\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6464 - binary_accuracy: 0.6308\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6554 - binary_accuracy: 0.6418\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6492 - binary_accuracy: 0.6374\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6486 - binary_accuracy: 0.6374\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6422 - binary_accuracy: 0.6440\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6449 - binary_accuracy: 0.6396\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6464 - binary_accuracy: 0.6396\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6422 - binary_accuracy: 0.6396\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6476 - binary_accuracy: 0.6418\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6445 - binary_accuracy: 0.6462\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6427 - binary_accuracy: 0.6308\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6370 - binary_accuracy: 0.6374\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6418 - binary_accuracy: 0.6396\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6348 - binary_accuracy: 0.6418\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.6377 - binary_accuracy: 0.6352\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6316 - binary_accuracy: 0.6505\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6427 - binary_accuracy: 0.6396\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6370 - binary_accuracy: 0.6462\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6296 - binary_accuracy: 0.6462\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6285 - binary_accuracy: 0.6396\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6428 - binary_accuracy: 0.6374\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6440\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6324 - binary_accuracy: 0.6418\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6364 - binary_accuracy: 0.6330\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6342 - binary_accuracy: 0.6396\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6341 - binary_accuracy: 0.6374\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6326 - binary_accuracy: 0.6418\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - binary_accuracy: 0.6418\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6328 - binary_accuracy: 0.6440\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - binary_accuracy: 0.6308\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6444 - binary_accuracy: 0.6308\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6337 - binary_accuracy: 0.6330\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6308\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6309 - binary_accuracy: 0.6374\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - binary_accuracy: 0.6242\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6315 - binary_accuracy: 0.6286\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6352\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6396\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6307 - binary_accuracy: 0.6220\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6205 - binary_accuracy: 0.6484\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6275 - binary_accuracy: 0.6374\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6270 - binary_accuracy: 0.6286\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6440\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6308\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - binary_accuracy: 0.6330\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6276 - binary_accuracy: 0.6659\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6440\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6288 - binary_accuracy: 0.6396\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6229 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - binary_accuracy: 0.6242\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6242 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - binary_accuracy: 0.6198\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6306 - binary_accuracy: 0.6264\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6290 - binary_accuracy: 0.6484\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - binary_accuracy: 0.6198\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6255 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6161 - binary_accuracy: 0.6484\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - binary_accuracy: 0.6286\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6549\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6236 - binary_accuracy: 0.6352\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6440\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6259 - binary_accuracy: 0.6527\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.6330\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6286 - binary_accuracy: 0.6396\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6348 - binary_accuracy: 0.6264\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6312 - binary_accuracy: 0.6440\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6222 - binary_accuracy: 0.6462\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6336 - binary_accuracy: 0.6396\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6396\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - binary_accuracy: 0.6330\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6192 - binary_accuracy: 0.6440\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - binary_accuracy: 0.6132\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6593\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.6396\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6440\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6214 - binary_accuracy: 0.6308\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - binary_accuracy: 0.6308\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6330\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6289 - binary_accuracy: 0.6176\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6154\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6181 - binary_accuracy: 0.6462\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6255 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6302 - binary_accuracy: 0.6220\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6207 - binary_accuracy: 0.6308\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6549\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.6264\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6223 - binary_accuracy: 0.6484\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6293 - binary_accuracy: 0.6264\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6220\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6274 - binary_accuracy: 0.6396\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6330\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6330\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6274 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6785 - binary_accuracy: 0.5451\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6783 - binary_accuracy: 0.5604\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6675 - binary_accuracy: 0.6132\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6594 - binary_accuracy: 0.6154\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6640 - binary_accuracy: 0.6154\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6616 - binary_accuracy: 0.6110\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6639 - binary_accuracy: 0.6220\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6589 - binary_accuracy: 0.6154\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6604 - binary_accuracy: 0.6110\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6551 - binary_accuracy: 0.6198\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6562 - binary_accuracy: 0.6176\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6612 - binary_accuracy: 0.6044\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6539 - binary_accuracy: 0.6198\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6500 - binary_accuracy: 0.6198\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6066\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6549 - binary_accuracy: 0.6132\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6528 - binary_accuracy: 0.6110\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6498 - binary_accuracy: 0.6242\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6176\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6550 - binary_accuracy: 0.5978\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - binary_accuracy: 0.6220\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6374\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6473 - binary_accuracy: 0.6132\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6540 - binary_accuracy: 0.5956\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6499 - binary_accuracy: 0.5934\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6553 - binary_accuracy: 0.5978\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - binary_accuracy: 0.6264\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - binary_accuracy: 0.6066\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6426 - binary_accuracy: 0.6176\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - binary_accuracy: 0.6308\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6527 - binary_accuracy: 0.5956\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - binary_accuracy: 0.6176\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - binary_accuracy: 0.6198\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.6176\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6455 - binary_accuracy: 0.6132\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6396\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6443 - binary_accuracy: 0.6374\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6528 - binary_accuracy: 0.6044\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6286\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6483 - binary_accuracy: 0.6044\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6264\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.6308\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6432 - binary_accuracy: 0.6044\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6286\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6044\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6264\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.6220\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6508 - binary_accuracy: 0.5934\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6376 - binary_accuracy: 0.6220\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6436 - binary_accuracy: 0.6176\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6421 - binary_accuracy: 0.6176\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6408 - binary_accuracy: 0.5956\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6408 - binary_accuracy: 0.5912\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6517 - binary_accuracy: 0.6132\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6132\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6467 - binary_accuracy: 0.6000\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6383 - binary_accuracy: 0.6110\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.6286\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6434 - binary_accuracy: 0.6198\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6417 - binary_accuracy: 0.6132\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6286\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6486 - binary_accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6541 - binary_accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - binary_accuracy: 0.6176\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - binary_accuracy: 0.6088\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6509 - binary_accuracy: 0.5934\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6553 - binary_accuracy: 0.5824\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - binary_accuracy: 0.6264\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - binary_accuracy: 0.6176\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6459 - binary_accuracy: 0.6176\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.6066\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.6110\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - binary_accuracy: 0.6088\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - binary_accuracy: 0.6286\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6110\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6439 - binary_accuracy: 0.6154\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6458 - binary_accuracy: 0.6044\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - binary_accuracy: 0.5934\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.5868\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6396\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - binary_accuracy: 0.6022\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6176\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - binary_accuracy: 0.6154\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6286\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6110\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - binary_accuracy: 0.6044\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6313 - binary_accuracy: 0.6154\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6427 - binary_accuracy: 0.6044\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.6176\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6454 - binary_accuracy: 0.6132\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.6352\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.6286\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6066\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - binary_accuracy: 0.5912\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - binary_accuracy: 0.6110\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6220\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6272 - binary_accuracy: 0.6264\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - binary_accuracy: 0.6132\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6066\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.7018 - binary_accuracy: 0.4857\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6884 - binary_accuracy: 0.5407\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6864 - binary_accuracy: 0.5407\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6849 - binary_accuracy: 0.5824\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6796 - binary_accuracy: 0.5648\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6741 - binary_accuracy: 0.5758\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6708 - binary_accuracy: 0.5912\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6762 - binary_accuracy: 0.5868\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6745 - binary_accuracy: 0.5780\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6728 - binary_accuracy: 0.5956\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6704 - binary_accuracy: 0.5692\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6607 - binary_accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6608 - binary_accuracy: 0.5846\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6620 - binary_accuracy: 0.5978\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6632 - binary_accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6594 - binary_accuracy: 0.5846\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6576 - binary_accuracy: 0.6066\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6613 - binary_accuracy: 0.5934\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6567 - binary_accuracy: 0.5868\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.5912\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6568 - binary_accuracy: 0.5824\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6618 - binary_accuracy: 0.5626\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6590 - binary_accuracy: 0.5736\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6532 - binary_accuracy: 0.5890\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6570 - binary_accuracy: 0.5802\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.5890\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6486 - binary_accuracy: 0.5934\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6562 - binary_accuracy: 0.5714\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6534 - binary_accuracy: 0.5868\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.5934\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.5692\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - binary_accuracy: 0.5956\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.5670\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6557 - binary_accuracy: 0.5824\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - binary_accuracy: 0.5824\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6512 - binary_accuracy: 0.5890\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.5780\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6503 - binary_accuracy: 0.5868\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - binary_accuracy: 0.6066\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.5956\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - binary_accuracy: 0.5868\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6580 - binary_accuracy: 0.5692\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6491 - binary_accuracy: 0.5802\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6481 - binary_accuracy: 0.5516\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6529 - binary_accuracy: 0.5604\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6484 - binary_accuracy: 0.6066\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6599 - binary_accuracy: 0.5758\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.5956\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6567 - binary_accuracy: 0.5692\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6524 - binary_accuracy: 0.5802\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6468 - binary_accuracy: 0.5538\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6479 - binary_accuracy: 0.5648\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.5846\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.5890\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.5890\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.5912\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.5670\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6457 - binary_accuracy: 0.5890\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6466 - binary_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.5956\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - binary_accuracy: 0.5802\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.5846\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - binary_accuracy: 0.5538\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6453 - binary_accuracy: 0.5714\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.5912\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - binary_accuracy: 0.6088\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6545 - binary_accuracy: 0.5626\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6536 - binary_accuracy: 0.5780\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.5956\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.5912\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.5758\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - binary_accuracy: 0.6176\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - binary_accuracy: 0.5736\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.5890\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.5495\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.5604\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6528 - binary_accuracy: 0.5780\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6497 - binary_accuracy: 0.5846\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - binary_accuracy: 0.5736\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - binary_accuracy: 0.6110\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.5714\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6447 - binary_accuracy: 0.5868\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6506 - binary_accuracy: 0.5758\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6448 - binary_accuracy: 0.5890\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.5868\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6357 - binary_accuracy: 0.5934\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6394 - binary_accuracy: 0.5868\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.5934\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6513 - binary_accuracy: 0.5956\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6176\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - binary_accuracy: 0.5560\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6110\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6562 - binary_accuracy: 0.5648\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6490 - binary_accuracy: 0.5604\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6446 - binary_accuracy: 0.5736\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - binary_accuracy: 0.5538\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6475 - binary_accuracy: 0.5846\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6509 - binary_accuracy: 0.5648\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6854 - binary_accuracy: 0.5263\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6765 - binary_accuracy: 0.5373\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6685 - binary_accuracy: 0.5943\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6745 - binary_accuracy: 0.5439\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6723 - binary_accuracy: 0.5855\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6695 - binary_accuracy: 0.5855\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6606 - binary_accuracy: 0.6140\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6687 - binary_accuracy: 0.5768\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6634 - binary_accuracy: 0.5943\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.6162\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6228\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.6118\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6759 - binary_accuracy: 0.5877\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6468 - binary_accuracy: 0.5987\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - binary_accuracy: 0.6009\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - binary_accuracy: 0.6206\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6075\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6360\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - binary_accuracy: 0.6228\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - binary_accuracy: 0.6118\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6250\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - binary_accuracy: 0.5702\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6677 - binary_accuracy: 0.5548\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6581 - binary_accuracy: 0.5789\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6653 - binary_accuracy: 0.5768\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5592\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6672 - binary_accuracy: 0.5351\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6679 - binary_accuracy: 0.5702\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6675 - binary_accuracy: 0.5461\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6520 - binary_accuracy: 0.5833\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6577 - binary_accuracy: 0.6009\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6603 - binary_accuracy: 0.5329\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6546 - binary_accuracy: 0.5658\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6615 - binary_accuracy: 0.5592\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - binary_accuracy: 0.5877\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6628 - binary_accuracy: 0.5899\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - binary_accuracy: 0.5965\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6594 - binary_accuracy: 0.5658\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6612 - binary_accuracy: 0.5658\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6549 - binary_accuracy: 0.5724\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6615 - binary_accuracy: 0.5680\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6562 - binary_accuracy: 0.5987\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6454 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6557 - binary_accuracy: 0.5833\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6499 - binary_accuracy: 0.5921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6540 - binary_accuracy: 0.5724\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6474 - binary_accuracy: 0.5855\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6513 - binary_accuracy: 0.5614\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6501 - binary_accuracy: 0.5833\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - binary_accuracy: 0.5724\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6503 - binary_accuracy: 0.5987\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6593 - binary_accuracy: 0.5702\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6464 - binary_accuracy: 0.6140\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6526 - binary_accuracy: 0.5965\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6507 - binary_accuracy: 0.5899\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6463 - binary_accuracy: 0.6009\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6454 - binary_accuracy: 0.6031\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6466 - binary_accuracy: 0.5921\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.5724\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - binary_accuracy: 0.5746\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - binary_accuracy: 0.5965\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.5943\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - binary_accuracy: 0.5811\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.5658\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6562 - binary_accuracy: 0.5439\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.5965\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6559 - binary_accuracy: 0.5570\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6492 - binary_accuracy: 0.5658\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - binary_accuracy: 0.5965\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6140\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - binary_accuracy: 0.5811\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.5636\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.5899\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - binary_accuracy: 0.5855\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - binary_accuracy: 0.5943\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6486 - binary_accuracy: 0.5658\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - binary_accuracy: 0.5680\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6518 - binary_accuracy: 0.5768\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - binary_accuracy: 0.6184\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6502 - binary_accuracy: 0.5702\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6466 - binary_accuracy: 0.5855\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.5789\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6610 - binary_accuracy: 0.5526\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - binary_accuracy: 0.5877\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - binary_accuracy: 0.5965\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - binary_accuracy: 0.5855\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6489 - binary_accuracy: 0.6053\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - binary_accuracy: 0.5833\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.5855\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6487 - binary_accuracy: 0.5680\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6517 - binary_accuracy: 0.5614\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - binary_accuracy: 0.5899\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.5680\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.5746\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.5702\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - binary_accuracy: 0.5724\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6573 - binary_accuracy: 0.5811\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6009\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 5ms/step - loss: 0.8093 - binary_accuracy: 0.5033\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7638 - binary_accuracy: 0.6198\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7319 - binary_accuracy: 0.6549\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7007 - binary_accuracy: 0.6747\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6838 - binary_accuracy: 0.6813\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6642 - binary_accuracy: 0.6835\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6563 - binary_accuracy: 0.6835\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6521 - binary_accuracy: 0.6835\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6460 - binary_accuracy: 0.6835\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6448 - binary_accuracy: 0.6835\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6432 - binary_accuracy: 0.6835\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6398 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6399 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6380 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6371 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6377 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6373 - binary_accuracy: 0.6835\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6371 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6364 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6369 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6360 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6363 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6355 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6355 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6352 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6341 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - binary_accuracy: 0.6835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6347 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6347 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6339 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6338 - binary_accuracy: 0.6835\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6835\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6857\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6321 - binary_accuracy: 0.6857\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.6857\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6327 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - binary_accuracy: 0.6857\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6325 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6323 - binary_accuracy: 0.6857\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6321 - binary_accuracy: 0.6857\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6323 - binary_accuracy: 0.6835\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6857\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6312 - binary_accuracy: 0.6857\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6835\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6326 - binary_accuracy: 0.6857\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6313 - binary_accuracy: 0.6857\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6321 - binary_accuracy: 0.6857\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6322 - binary_accuracy: 0.6857\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6309 - binary_accuracy: 0.6857\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6857\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6835\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6857\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6312 - binary_accuracy: 0.6857\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6879\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6857\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6314 - binary_accuracy: 0.6857\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6306 - binary_accuracy: 0.6857\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6312 - binary_accuracy: 0.6835\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6320 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6299 - binary_accuracy: 0.6879\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6319 - binary_accuracy: 0.6857\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 5ms/step - loss: 0.8434 - binary_accuracy: 0.5407\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7987 - binary_accuracy: 0.6527\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7766 - binary_accuracy: 0.6462\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7627 - binary_accuracy: 0.6418\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - binary_accuracy: 0.6396\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7364 - binary_accuracy: 0.6462\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7383 - binary_accuracy: 0.6374\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7271 - binary_accuracy: 0.6440\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7307 - binary_accuracy: 0.6440\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7279 - binary_accuracy: 0.6462\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7214 - binary_accuracy: 0.6549\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7228 - binary_accuracy: 0.6505\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7201 - binary_accuracy: 0.6484\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7145 - binary_accuracy: 0.6571\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7259 - binary_accuracy: 0.6440\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7182 - binary_accuracy: 0.6440\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7039 - binary_accuracy: 0.6484\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7019 - binary_accuracy: 0.6549\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6964 - binary_accuracy: 0.6681\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7012 - binary_accuracy: 0.6725\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7104 - binary_accuracy: 0.6571\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7131 - binary_accuracy: 0.6505\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7030 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7067 - binary_accuracy: 0.6769\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7022 - binary_accuracy: 0.6769\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7054 - binary_accuracy: 0.6813\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7079 - binary_accuracy: 0.6615\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6952 - binary_accuracy: 0.6747\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7000 - binary_accuracy: 0.6593\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6919 - binary_accuracy: 0.6857\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6890 - binary_accuracy: 0.6769\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7007 - binary_accuracy: 0.6769\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7028 - binary_accuracy: 0.6681\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7054 - binary_accuracy: 0.6505\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7058 - binary_accuracy: 0.6505\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7036 - binary_accuracy: 0.6593\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7229 - binary_accuracy: 0.6242\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7111 - binary_accuracy: 0.6527\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7220 - binary_accuracy: 0.6352\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7070 - binary_accuracy: 0.6593\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7098 - binary_accuracy: 0.6527\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7044 - binary_accuracy: 0.6659\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7061 - binary_accuracy: 0.6615\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6969 - binary_accuracy: 0.6659\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6946 - binary_accuracy: 0.6659\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7094 - binary_accuracy: 0.6593\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7086 - binary_accuracy: 0.6615\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6937 - binary_accuracy: 0.6703\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6894 - binary_accuracy: 0.6857\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7126 - binary_accuracy: 0.6549\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6893 - binary_accuracy: 0.6901\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6863 - binary_accuracy: 0.6989\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6993 - binary_accuracy: 0.6791\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6844 - binary_accuracy: 0.6791\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7018 - binary_accuracy: 0.6637\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7013 - binary_accuracy: 0.6659\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7107 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7057 - binary_accuracy: 0.6593\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7052 - binary_accuracy: 0.6462\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7103 - binary_accuracy: 0.6527\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7181 - binary_accuracy: 0.6308\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6975 - binary_accuracy: 0.6791\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6903 - binary_accuracy: 0.6791\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - binary_accuracy: 0.6813\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6900 - binary_accuracy: 0.6813\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6908 - binary_accuracy: 0.6703\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6747 - binary_accuracy: 0.6989\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6684 - binary_accuracy: 0.7077\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6771 - binary_accuracy: 0.6945\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.7187\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6870 - binary_accuracy: 0.6747\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6873 - binary_accuracy: 0.6813\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - binary_accuracy: 0.6681\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6879 - binary_accuracy: 0.6703\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6729 - binary_accuracy: 0.7011\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6890 - binary_accuracy: 0.6725\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6734 - binary_accuracy: 0.7033\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7001 - binary_accuracy: 0.6703\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6993 - binary_accuracy: 0.6440\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7053 - binary_accuracy: 0.6637\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7092 - binary_accuracy: 0.6462\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6901 - binary_accuracy: 0.6791\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6834 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6929 - binary_accuracy: 0.6813\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6758 - binary_accuracy: 0.6989\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6843 - binary_accuracy: 0.6901\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6859 - binary_accuracy: 0.6769\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6861 - binary_accuracy: 0.6813\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6778 - binary_accuracy: 0.6879\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - binary_accuracy: 0.6637\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6832 - binary_accuracy: 0.6901\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6938 - binary_accuracy: 0.6725\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7015 - binary_accuracy: 0.6659\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6791 - binary_accuracy: 0.6901\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6857 - binary_accuracy: 0.6879\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7019 - binary_accuracy: 0.6571\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7006 - binary_accuracy: 0.6549\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6771 - binary_accuracy: 0.6923\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6972 - binary_accuracy: 0.6681\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6884 - binary_accuracy: 0.6681\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.8609 - binary_accuracy: 0.5846\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8320 - binary_accuracy: 0.6220\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8074 - binary_accuracy: 0.6264\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7919 - binary_accuracy: 0.6220\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7849 - binary_accuracy: 0.6220\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7791 - binary_accuracy: 0.6220\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7713 - binary_accuracy: 0.6220\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7688 - binary_accuracy: 0.6286\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7699 - binary_accuracy: 0.6220\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7659 - binary_accuracy: 0.6220\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7699 - binary_accuracy: 0.6220\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7632 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7613 - binary_accuracy: 0.6264\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7614 - binary_accuracy: 0.6220\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7601 - binary_accuracy: 0.6242\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7601 - binary_accuracy: 0.6286\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7630 - binary_accuracy: 0.6198\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7591 - binary_accuracy: 0.6220\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7547 - binary_accuracy: 0.6220\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7579 - binary_accuracy: 0.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7591 - binary_accuracy: 0.6220\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7605 - binary_accuracy: 0.6220\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7591 - binary_accuracy: 0.6220\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7577 - binary_accuracy: 0.6242\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7559 - binary_accuracy: 0.6220\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7506 - binary_accuracy: 0.6242\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7508 - binary_accuracy: 0.6242\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7551 - binary_accuracy: 0.6242\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7488 - binary_accuracy: 0.6242\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7608 - binary_accuracy: 0.6198\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7578 - binary_accuracy: 0.6264\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7427 - binary_accuracy: 0.6286\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7399 - binary_accuracy: 0.6440\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7393 - binary_accuracy: 0.6396\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7287 - binary_accuracy: 0.6505\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7337 - binary_accuracy: 0.6330\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7640 - binary_accuracy: 0.6154\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7406 - binary_accuracy: 0.6593\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7522 - binary_accuracy: 0.6462\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7279 - binary_accuracy: 0.6681\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7507 - binary_accuracy: 0.6242\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7275 - binary_accuracy: 0.6747\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - binary_accuracy: 0.6462\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7275 - binary_accuracy: 0.6681\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - binary_accuracy: 0.6440\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7388 - binary_accuracy: 0.6440\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - binary_accuracy: 0.6505\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7298 - binary_accuracy: 0.6593\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7286 - binary_accuracy: 0.6659\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - binary_accuracy: 0.6527\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - binary_accuracy: 0.6484\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7266 - binary_accuracy: 0.6615\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7259 - binary_accuracy: 0.6593\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7104 - binary_accuracy: 0.6747\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7191 - binary_accuracy: 0.6549\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7185 - binary_accuracy: 0.6615\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - binary_accuracy: 0.6286\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7235 - binary_accuracy: 0.6484\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - binary_accuracy: 0.6571\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7397 - binary_accuracy: 0.6484\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7302 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7128 - binary_accuracy: 0.6681\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7248 - binary_accuracy: 0.6484\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7402 - binary_accuracy: 0.6418\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7431 - binary_accuracy: 0.6440\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - binary_accuracy: 0.6462\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7269 - binary_accuracy: 0.6659\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - binary_accuracy: 0.6571\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7244 - binary_accuracy: 0.6571\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6886 - binary_accuracy: 0.7033\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7233 - binary_accuracy: 0.6549\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7090 - binary_accuracy: 0.6747\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7242 - binary_accuracy: 0.6505\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7412 - binary_accuracy: 0.6396\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7112 - binary_accuracy: 0.6747\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7406 - binary_accuracy: 0.6462\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7131 - binary_accuracy: 0.6615\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7234 - binary_accuracy: 0.6593\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7084 - binary_accuracy: 0.6659\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7070 - binary_accuracy: 0.6857\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7119 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7155 - binary_accuracy: 0.6615\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7135 - binary_accuracy: 0.6725\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7214 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6984 - binary_accuracy: 0.6945\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7181 - binary_accuracy: 0.6615\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7092 - binary_accuracy: 0.6681\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7171 - binary_accuracy: 0.6703\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7151 - binary_accuracy: 0.6703\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6945 - binary_accuracy: 0.6967\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7146 - binary_accuracy: 0.6615\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7197 - binary_accuracy: 0.6637\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6980 - binary_accuracy: 0.6901\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7219 - binary_accuracy: 0.6615\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7035 - binary_accuracy: 0.6923\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7003 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7178 - binary_accuracy: 0.6571\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6854 - binary_accuracy: 0.7143\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8820 - binary_accuracy: 0.5473\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8711 - binary_accuracy: 0.5824\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8608 - binary_accuracy: 0.5912\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8569 - binary_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8438 - binary_accuracy: 0.5978\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8289 - binary_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8253 - binary_accuracy: 0.5978\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8180 - binary_accuracy: 0.5978\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8200 - binary_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8149 - binary_accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8077 - binary_accuracy: 0.5956\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8090 - binary_accuracy: 0.5978\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8110 - binary_accuracy: 0.6044\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8089 - binary_accuracy: 0.5978\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8065 - binary_accuracy: 0.6022\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8115 - binary_accuracy: 0.5912\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8022 - binary_accuracy: 0.6044\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8028 - binary_accuracy: 0.6022\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8030 - binary_accuracy: 0.6022\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7836 - binary_accuracy: 0.6088\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7732 - binary_accuracy: 0.6198\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7806 - binary_accuracy: 0.6484\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7701 - binary_accuracy: 0.6593\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7830 - binary_accuracy: 0.6396\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7970 - binary_accuracy: 0.6242\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7958 - binary_accuracy: 0.6220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8023 - binary_accuracy: 0.6044\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7953 - binary_accuracy: 0.6022\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7837 - binary_accuracy: 0.6176\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7972 - binary_accuracy: 0.6022\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7860 - binary_accuracy: 0.6220\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7524 - binary_accuracy: 0.7033\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7714 - binary_accuracy: 0.6308\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7677 - binary_accuracy: 0.6681\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7522 - binary_accuracy: 0.6615\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - binary_accuracy: 0.6901\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7624 - binary_accuracy: 0.6571\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7310 - binary_accuracy: 0.7099\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7246 - binary_accuracy: 0.7143\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - binary_accuracy: 0.6725\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7772 - binary_accuracy: 0.6374\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7690 - binary_accuracy: 0.6527\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6967\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7019 - binary_accuracy: 0.7209\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7162 - binary_accuracy: 0.7033\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7009 - binary_accuracy: 0.7407\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6972 - binary_accuracy: 0.7495\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7059 - binary_accuracy: 0.7297\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7232 - binary_accuracy: 0.7121\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6892 - binary_accuracy: 0.7495\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6979 - binary_accuracy: 0.7231\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6878 - binary_accuracy: 0.7429\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7258 - binary_accuracy: 0.6901\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7235 - binary_accuracy: 0.6967\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7144 - binary_accuracy: 0.6989\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6565 - binary_accuracy: 0.7824\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6833 - binary_accuracy: 0.7297\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6924 - binary_accuracy: 0.7209\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6618 - binary_accuracy: 0.7538\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.7736\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6624 - binary_accuracy: 0.7582\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6467 - binary_accuracy: 0.7802\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - binary_accuracy: 0.7670\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6630 - binary_accuracy: 0.7714\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6827 - binary_accuracy: 0.7407\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.7604\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6370 - binary_accuracy: 0.7802\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6471 - binary_accuracy: 0.7736\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.7714\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6240 - binary_accuracy: 0.8110\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6337 - binary_accuracy: 0.7846\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6128 - binary_accuracy: 0.8066\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6100 - binary_accuracy: 0.8110\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6220 - binary_accuracy: 0.7846\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.8154\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6007 - binary_accuracy: 0.8110\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6163 - binary_accuracy: 0.8044\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - binary_accuracy: 0.7890\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6251 - binary_accuracy: 0.7956\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6224 - binary_accuracy: 0.7934\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5923 - binary_accuracy: 0.8220\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.8022\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6669 - binary_accuracy: 0.7385\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - binary_accuracy: 0.7648\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - binary_accuracy: 0.7758\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6403 - binary_accuracy: 0.7626\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6548 - binary_accuracy: 0.7560\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6988 - binary_accuracy: 0.7165\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7082 - binary_accuracy: 0.6967\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6796 - binary_accuracy: 0.7253\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6196 - binary_accuracy: 0.7890\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6759 - binary_accuracy: 0.7341\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6259 - binary_accuracy: 0.7824\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.7780\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - binary_accuracy: 0.7692\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - binary_accuracy: 0.7626\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.7890\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6230 - binary_accuracy: 0.7868\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6192 - binary_accuracy: 0.7912\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5851 - binary_accuracy: 0.8330\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.8926 - binary_accuracy: 0.5833\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8803 - binary_accuracy: 0.5899\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8653 - binary_accuracy: 0.5899\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8571 - binary_accuracy: 0.5921\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8504 - binary_accuracy: 0.5855\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8408 - binary_accuracy: 0.5855\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8369 - binary_accuracy: 0.5921\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8307 - binary_accuracy: 0.5921\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8253 - binary_accuracy: 0.5921\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8311 - binary_accuracy: 0.5789\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8228 - binary_accuracy: 0.5855\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8269 - binary_accuracy: 0.5899\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8159 - binary_accuracy: 0.5833\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8097 - binary_accuracy: 0.5921\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8155 - binary_accuracy: 0.5768\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8039 - binary_accuracy: 0.6360\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8001 - binary_accuracy: 0.6272\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7929 - binary_accuracy: 0.6601\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7871 - binary_accuracy: 0.6469\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7684 - binary_accuracy: 0.6732\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7993 - binary_accuracy: 0.6294\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7842 - binary_accuracy: 0.6250\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7597 - binary_accuracy: 0.6952\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - binary_accuracy: 0.6798\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7930 - binary_accuracy: 0.6228\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7633 - binary_accuracy: 0.6557\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7488 - binary_accuracy: 0.6974\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - binary_accuracy: 0.6886\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7613 - binary_accuracy: 0.6447\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - binary_accuracy: 0.6798\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7614 - binary_accuracy: 0.6711\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7705 - binary_accuracy: 0.6360\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7311 - binary_accuracy: 0.7105\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7273 - binary_accuracy: 0.7171\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7336 - binary_accuracy: 0.7171\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7336 - binary_accuracy: 0.6820\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7342 - binary_accuracy: 0.6952\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7281 - binary_accuracy: 0.7061\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7257 - binary_accuracy: 0.7018\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7563 - binary_accuracy: 0.6754\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7455 - binary_accuracy: 0.6842\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7522 - binary_accuracy: 0.6820\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7516 - binary_accuracy: 0.6689\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7466 - binary_accuracy: 0.6732\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7398 - binary_accuracy: 0.6996\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7568 - binary_accuracy: 0.6601\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7408 - binary_accuracy: 0.6930\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7283 - binary_accuracy: 0.7039\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7366 - binary_accuracy: 0.6776\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7672 - binary_accuracy: 0.6491\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7677 - binary_accuracy: 0.6469\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7672 - binary_accuracy: 0.6689\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7506 - binary_accuracy: 0.6645\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7658 - binary_accuracy: 0.6732\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7509 - binary_accuracy: 0.6579\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7860 - binary_accuracy: 0.6382\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7753 - binary_accuracy: 0.6382\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7271 - binary_accuracy: 0.6974\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - binary_accuracy: 0.6711\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7203 - binary_accuracy: 0.7039\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7308 - binary_accuracy: 0.6864\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7336 - binary_accuracy: 0.6864\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7228 - binary_accuracy: 0.6908\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7286 - binary_accuracy: 0.6908\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7120 - binary_accuracy: 0.7061\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7159 - binary_accuracy: 0.7083\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7243 - binary_accuracy: 0.6864\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7455 - binary_accuracy: 0.6689\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7247 - binary_accuracy: 0.6908\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - binary_accuracy: 0.6842\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - binary_accuracy: 0.6689\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7241 - binary_accuracy: 0.6996\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7305 - binary_accuracy: 0.6974\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7517 - binary_accuracy: 0.6645\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7180 - binary_accuracy: 0.6886\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7159 - binary_accuracy: 0.7018\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7171 - binary_accuracy: 0.6930\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7101 - binary_accuracy: 0.7061\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7140 - binary_accuracy: 0.7061\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7202 - binary_accuracy: 0.6930\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7428 - binary_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7542 - binary_accuracy: 0.6689\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7274 - binary_accuracy: 0.6864\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7356 - binary_accuracy: 0.6798\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - binary_accuracy: 0.6711\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7328 - binary_accuracy: 0.6754\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7226 - binary_accuracy: 0.6996\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7238 - binary_accuracy: 0.6864\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7320 - binary_accuracy: 0.6776\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7348 - binary_accuracy: 0.6842\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - binary_accuracy: 0.6689\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - binary_accuracy: 0.6798\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7329 - binary_accuracy: 0.6996\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7204 - binary_accuracy: 0.6930\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7252 - binary_accuracy: 0.6886\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7293 - binary_accuracy: 0.6886\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - binary_accuracy: 0.6711\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7336 - binary_accuracy: 0.6908\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7283 - binary_accuracy: 0.6864\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7287 - binary_accuracy: 0.6776\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 5ms/step - loss: 0.8181 - binary_accuracy: 0.5121\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7828 - binary_accuracy: 0.6396\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7529 - binary_accuracy: 0.6505\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7349 - binary_accuracy: 0.6637\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7207 - binary_accuracy: 0.6681\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7120 - binary_accuracy: 0.6725\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7019 - binary_accuracy: 0.6725\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6957 - binary_accuracy: 0.6725\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6912 - binary_accuracy: 0.6769\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6854 - binary_accuracy: 0.6791\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6770 - binary_accuracy: 0.6791\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6813 - binary_accuracy: 0.6813\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6740 - binary_accuracy: 0.6813\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6705 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6711 - binary_accuracy: 0.6791\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6664 - binary_accuracy: 0.6813\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6673 - binary_accuracy: 0.6791\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6641 - binary_accuracy: 0.6791\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6635 - binary_accuracy: 0.6813\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6595 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6645 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6603 - binary_accuracy: 0.6813\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6609 - binary_accuracy: 0.6769\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6578 - binary_accuracy: 0.6791\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6575 - binary_accuracy: 0.6813\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6579 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6573 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6589 - binary_accuracy: 0.6791\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6525 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6547 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6501 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.6813\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6520 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6492 - binary_accuracy: 0.6813\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6499 - binary_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6506 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6477 - binary_accuracy: 0.6813\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6509 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6462 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - binary_accuracy: 0.6813\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.6813\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6456 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6480 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - binary_accuracy: 0.6813\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - binary_accuracy: 0.6813\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6461 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6429 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6446 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6835\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6446 - binary_accuracy: 0.6835\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6431 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6426 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6448 - binary_accuracy: 0.6835\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.6813\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6431 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.6835\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6411 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6813\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6422 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6835\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6835\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6835\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - binary_accuracy: 0.6791\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - binary_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6403 - binary_accuracy: 0.6835\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6405 - binary_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - binary_accuracy: 0.6813\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - binary_accuracy: 0.6835\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - binary_accuracy: 0.6835\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - binary_accuracy: 0.6835\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6401 - binary_accuracy: 0.6835\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - binary_accuracy: 0.6813\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6390 - binary_accuracy: 0.6835\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6406 - binary_accuracy: 0.6835\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6405 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - binary_accuracy: 0.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6405 - binary_accuracy: 0.6835\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8476 - binary_accuracy: 0.5429\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8391 - binary_accuracy: 0.5956\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8178 - binary_accuracy: 0.6198\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8144 - binary_accuracy: 0.6264\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8062 - binary_accuracy: 0.6286\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7962 - binary_accuracy: 0.6352\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7918 - binary_accuracy: 0.6352\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7856 - binary_accuracy: 0.6352\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7778 - binary_accuracy: 0.6352\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7727 - binary_accuracy: 0.6396\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7716 - binary_accuracy: 0.6396\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7649 - binary_accuracy: 0.6374\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7723 - binary_accuracy: 0.6396\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7640 - binary_accuracy: 0.6418\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7613 - binary_accuracy: 0.6396\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7636 - binary_accuracy: 0.6374\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7548 - binary_accuracy: 0.6396\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - binary_accuracy: 0.6396\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - binary_accuracy: 0.6396\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7506 - binary_accuracy: 0.6396\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - binary_accuracy: 0.6418\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7489 - binary_accuracy: 0.6418\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7515 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7452 - binary_accuracy: 0.6396\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - binary_accuracy: 0.6396\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7455 - binary_accuracy: 0.6418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - binary_accuracy: 0.6418\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - binary_accuracy: 0.6396\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - binary_accuracy: 0.6418\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - binary_accuracy: 0.6396\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - binary_accuracy: 0.6418\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - binary_accuracy: 0.6396\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - binary_accuracy: 0.6418\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - binary_accuracy: 0.6418\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - binary_accuracy: 0.6396\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7385 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7363 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - binary_accuracy: 0.6440\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - binary_accuracy: 0.6418\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - binary_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - binary_accuracy: 0.6418\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - binary_accuracy: 0.6418\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7325 - binary_accuracy: 0.6418\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7325 - binary_accuracy: 0.6418\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7318 - binary_accuracy: 0.6418\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7319 - binary_accuracy: 0.6418\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7326 - binary_accuracy: 0.6396\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7325 - binary_accuracy: 0.6418\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - binary_accuracy: 0.6396\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7336 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7331 - binary_accuracy: 0.6396\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7310 - binary_accuracy: 0.6418\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7312 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7302 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7295 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7298 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7289 - binary_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7308 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7291 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7289 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7294 - binary_accuracy: 0.6396\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7267 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6418\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7286 - binary_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7291 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7281 - binary_accuracy: 0.6418\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7286 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7265 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7259 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7274 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7277 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7279 - binary_accuracy: 0.6418\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7265 - binary_accuracy: 0.6418\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7286 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7287 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7267 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7263 - binary_accuracy: 0.6418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7259 - binary_accuracy: 0.6418\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7248 - binary_accuracy: 0.6418\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7287 - binary_accuracy: 0.6396\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7270 - binary_accuracy: 0.6418\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7242 - binary_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7262 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7258 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7250 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7235 - binary_accuracy: 0.6440\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7256 - binary_accuracy: 0.6418\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7236 - binary_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7264 - binary_accuracy: 0.6396\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7248 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7254 - binary_accuracy: 0.6418\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7256 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7239 - binary_accuracy: 0.6418\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7270 - binary_accuracy: 0.6418\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7244 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8578 - binary_accuracy: 0.5780\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8525 - binary_accuracy: 0.5934\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8356 - binary_accuracy: 0.6154\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8320 - binary_accuracy: 0.6220\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8194 - binary_accuracy: 0.6220\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8154 - binary_accuracy: 0.6198\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8139 - binary_accuracy: 0.6198\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8091 - binary_accuracy: 0.6220\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7992 - binary_accuracy: 0.6242\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8033 - binary_accuracy: 0.6198\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7926 - binary_accuracy: 0.6220\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7922 - binary_accuracy: 0.6198\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7923 - binary_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7900 - binary_accuracy: 0.6220\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7877 - binary_accuracy: 0.6220\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7892 - binary_accuracy: 0.6220\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7854 - binary_accuracy: 0.6220\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7854 - binary_accuracy: 0.6220\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7849 - binary_accuracy: 0.6220\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7824 - binary_accuracy: 0.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7787 - binary_accuracy: 0.6198\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7791 - binary_accuracy: 0.6220\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7799 - binary_accuracy: 0.6220\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7774 - binary_accuracy: 0.6198\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7765 - binary_accuracy: 0.6220\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7759 - binary_accuracy: 0.6220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7774 - binary_accuracy: 0.6220\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7763 - binary_accuracy: 0.6220\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7781 - binary_accuracy: 0.6220\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7752 - binary_accuracy: 0.6220\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7740 - binary_accuracy: 0.6220\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7712 - binary_accuracy: 0.6220\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7747 - binary_accuracy: 0.6220\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7722 - binary_accuracy: 0.6220\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7703 - binary_accuracy: 0.6220\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7742 - binary_accuracy: 0.6220\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7693 - binary_accuracy: 0.6220\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7706 - binary_accuracy: 0.6220\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7726 - binary_accuracy: 0.6220\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7677 - binary_accuracy: 0.6220\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7682 - binary_accuracy: 0.6220\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7701 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7671 - binary_accuracy: 0.6220\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7710 - binary_accuracy: 0.6220\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7714 - binary_accuracy: 0.6220\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7674 - binary_accuracy: 0.6220\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7670 - binary_accuracy: 0.6220\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7664 - binary_accuracy: 0.6242\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7679 - binary_accuracy: 0.6220\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7649 - binary_accuracy: 0.6220\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7705 - binary_accuracy: 0.6220\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7677 - binary_accuracy: 0.6220\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7666 - binary_accuracy: 0.6198\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7675 - binary_accuracy: 0.6220\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7658 - binary_accuracy: 0.6220\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7699 - binary_accuracy: 0.6220\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7653 - binary_accuracy: 0.6220\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7649 - binary_accuracy: 0.6220\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7667 - binary_accuracy: 0.6220\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7646 - binary_accuracy: 0.6220\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - binary_accuracy: 0.6198\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7654 - binary_accuracy: 0.6220\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7629 - binary_accuracy: 0.6220\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - binary_accuracy: 0.6242\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7644 - binary_accuracy: 0.6220\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7656 - binary_accuracy: 0.6220\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7638 - binary_accuracy: 0.6220\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7639 - binary_accuracy: 0.6220\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7639 - binary_accuracy: 0.6220\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7647 - binary_accuracy: 0.6220\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7624 - binary_accuracy: 0.6220\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7645 - binary_accuracy: 0.6220\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7605 - binary_accuracy: 0.6220\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7630 - binary_accuracy: 0.6220\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7620 - binary_accuracy: 0.6220\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7627 - binary_accuracy: 0.6220\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7632 - binary_accuracy: 0.6220\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7627 - binary_accuracy: 0.6220\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7636 - binary_accuracy: 0.6220\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7629 - binary_accuracy: 0.6220\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7642 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7639 - binary_accuracy: 0.6220\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7623 - binary_accuracy: 0.6220\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7604 - binary_accuracy: 0.6220\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - binary_accuracy: 0.6220\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7632 - binary_accuracy: 0.6220\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - binary_accuracy: 0.6220\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7616 - binary_accuracy: 0.6220\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7644 - binary_accuracy: 0.6220\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7620 - binary_accuracy: 0.6220\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7633 - binary_accuracy: 0.6220\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7630 - binary_accuracy: 0.6220\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7617 - binary_accuracy: 0.6220\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7619 - binary_accuracy: 0.6220\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - binary_accuracy: 0.6220\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7619 - binary_accuracy: 0.6220\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7612 - binary_accuracy: 0.6220\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7647 - binary_accuracy: 0.6220\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 5ms/step - loss: 0.9126 - binary_accuracy: 0.4462\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9058 - binary_accuracy: 0.4615\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8984 - binary_accuracy: 0.5363\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8946 - binary_accuracy: 0.5495\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8863 - binary_accuracy: 0.5780\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8811 - binary_accuracy: 0.5824\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8815 - binary_accuracy: 0.5692\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8741 - binary_accuracy: 0.5890\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8661 - binary_accuracy: 0.5934\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8642 - binary_accuracy: 0.5868\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8581 - binary_accuracy: 0.5912\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8570 - binary_accuracy: 0.5912\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8570 - binary_accuracy: 0.5846\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8550 - binary_accuracy: 0.5890\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8468 - binary_accuracy: 0.5978\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8431 - binary_accuracy: 0.5912\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8482 - binary_accuracy: 0.5978\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8424 - binary_accuracy: 0.5912\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8412 - binary_accuracy: 0.5934\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8414 - binary_accuracy: 0.5912\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8400 - binary_accuracy: 0.5912\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8427 - binary_accuracy: 0.5868\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8405 - binary_accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8374 - binary_accuracy: 0.5890\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8389 - binary_accuracy: 0.5912\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8354 - binary_accuracy: 0.5890\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8369 - binary_accuracy: 0.5890\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8368 - binary_accuracy: 0.5934\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8335 - binary_accuracy: 0.5956\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8287 - binary_accuracy: 0.5934\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8287 - binary_accuracy: 0.5912\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8341 - binary_accuracy: 0.5956\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8347 - binary_accuracy: 0.5956\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8289 - binary_accuracy: 0.5956\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8269 - binary_accuracy: 0.5956\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8304 - binary_accuracy: 0.5934\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8289 - binary_accuracy: 0.5956\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8262 - binary_accuracy: 0.5912\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8293 - binary_accuracy: 0.5934\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8261 - binary_accuracy: 0.5956\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8280 - binary_accuracy: 0.5890\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8246 - binary_accuracy: 0.5934\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8262 - binary_accuracy: 0.5912\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8256 - binary_accuracy: 0.5890\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8227 - binary_accuracy: 0.6022\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.5934\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8229 - binary_accuracy: 0.5912\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8225 - binary_accuracy: 0.5978\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8245 - binary_accuracy: 0.5978\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8261 - binary_accuracy: 0.5934\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8234 - binary_accuracy: 0.5956\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8222 - binary_accuracy: 0.5978\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8213 - binary_accuracy: 0.5978\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8212 - binary_accuracy: 0.5956\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8240 - binary_accuracy: 0.5934\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8227 - binary_accuracy: 0.5978\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8239 - binary_accuracy: 0.5956\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8216 - binary_accuracy: 0.5956\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8192 - binary_accuracy: 0.5934\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8211 - binary_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8206 - binary_accuracy: 0.5934\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8201 - binary_accuracy: 0.5934\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8180 - binary_accuracy: 0.5978\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8196 - binary_accuracy: 0.5934\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5912\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8180 - binary_accuracy: 0.5978\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8183 - binary_accuracy: 0.5956\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8208 - binary_accuracy: 0.5934\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8196 - binary_accuracy: 0.5934\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5978\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8206 - binary_accuracy: 0.5956\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8193 - binary_accuracy: 0.5956\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8206 - binary_accuracy: 0.5956\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8191 - binary_accuracy: 0.5934\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8159 - binary_accuracy: 0.5978\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8162 - binary_accuracy: 0.5978\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8174 - binary_accuracy: 0.5956\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.5956\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8215 - binary_accuracy: 0.5934\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5956\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8178 - binary_accuracy: 0.5956\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8150 - binary_accuracy: 0.5978\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8171 - binary_accuracy: 0.5912\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8157 - binary_accuracy: 0.5956\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8172 - binary_accuracy: 0.5956\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8181 - binary_accuracy: 0.5956\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8140 - binary_accuracy: 0.5978\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8158 - binary_accuracy: 0.5978\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8166 - binary_accuracy: 0.5978\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8161 - binary_accuracy: 0.5978\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8157 - binary_accuracy: 0.5978\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8173 - binary_accuracy: 0.5956\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8172 - binary_accuracy: 0.5978\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8150 - binary_accuracy: 0.5956\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8146 - binary_accuracy: 0.5978\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8157 - binary_accuracy: 0.5978\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8179 - binary_accuracy: 0.5912\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8191 - binary_accuracy: 0.5956\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.9018 - binary_accuracy: 0.5285\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8928 - binary_accuracy: 0.5724\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8899 - binary_accuracy: 0.5899\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8857 - binary_accuracy: 0.5811\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8824 - binary_accuracy: 0.5833\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8799 - binary_accuracy: 0.5877\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8734 - binary_accuracy: 0.5921\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8752 - binary_accuracy: 0.5899\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8697 - binary_accuracy: 0.5921\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8678 - binary_accuracy: 0.5921\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8694 - binary_accuracy: 0.5921\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8605 - binary_accuracy: 0.5921\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8573 - binary_accuracy: 0.5921\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8603 - binary_accuracy: 0.5921\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8539 - binary_accuracy: 0.5921\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8576 - binary_accuracy: 0.5921\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8518 - binary_accuracy: 0.5921\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8506 - binary_accuracy: 0.5921\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8518 - binary_accuracy: 0.5921\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8505 - binary_accuracy: 0.5921\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8501 - binary_accuracy: 0.5921\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8469 - binary_accuracy: 0.5921\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8423 - binary_accuracy: 0.5921\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8423 - binary_accuracy: 0.5921\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8444 - binary_accuracy: 0.5921\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8421 - binary_accuracy: 0.5921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8420 - binary_accuracy: 0.5921\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8432 - binary_accuracy: 0.5921\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8374 - binary_accuracy: 0.5921\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8404 - binary_accuracy: 0.5921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8394 - binary_accuracy: 0.5921\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8348 - binary_accuracy: 0.5921\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8376 - binary_accuracy: 0.5921\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8377 - binary_accuracy: 0.5921\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8383 - binary_accuracy: 0.5921\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8362 - binary_accuracy: 0.5921\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8331 - binary_accuracy: 0.5921\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8362 - binary_accuracy: 0.5921\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8319 - binary_accuracy: 0.5921\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8325 - binary_accuracy: 0.5921\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8307 - binary_accuracy: 0.5921\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8331 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8331 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8312 - binary_accuracy: 0.5921\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8301 - binary_accuracy: 0.5921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8289 - binary_accuracy: 0.5921\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8290 - binary_accuracy: 0.5921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8297 - binary_accuracy: 0.5921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8296 - binary_accuracy: 0.5921\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8313 - binary_accuracy: 0.5921\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8313 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8282 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8315 - binary_accuracy: 0.5921\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8278 - binary_accuracy: 0.5921\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8307 - binary_accuracy: 0.5921\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8291 - binary_accuracy: 0.5921\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8297 - binary_accuracy: 0.5921\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8304 - binary_accuracy: 0.5921\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8304 - binary_accuracy: 0.5921\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8291 - binary_accuracy: 0.5921\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8282 - binary_accuracy: 0.5921\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8306 - binary_accuracy: 0.5921\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8296 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8272 - binary_accuracy: 0.5921\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8272 - binary_accuracy: 0.5921\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8255 - binary_accuracy: 0.5921\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8259 - binary_accuracy: 0.5921\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8281 - binary_accuracy: 0.5921\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8275 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8283 - binary_accuracy: 0.5921\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8273 - binary_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8267 - binary_accuracy: 0.5921\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8256 - binary_accuracy: 0.5921\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8279 - binary_accuracy: 0.5921\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8239 - binary_accuracy: 0.5921\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8259 - binary_accuracy: 0.5921\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8238 - binary_accuracy: 0.5921\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8246 - binary_accuracy: 0.5921\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8251 - binary_accuracy: 0.5921\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8247 - binary_accuracy: 0.5921\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8242 - binary_accuracy: 0.5921\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8238 - binary_accuracy: 0.5921\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8247 - binary_accuracy: 0.5921\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8247 - binary_accuracy: 0.5921\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8245 - binary_accuracy: 0.5921\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8239 - binary_accuracy: 0.5921\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8249 - binary_accuracy: 0.5921\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8238 - binary_accuracy: 0.5921\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8229 - binary_accuracy: 0.5921\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8229 - binary_accuracy: 0.5921\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8247 - binary_accuracy: 0.5921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8229 - binary_accuracy: 0.5921\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8225 - binary_accuracy: 0.5921\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8228 - binary_accuracy: 0.5921\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8212 - binary_accuracy: 0.5921\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8234 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8246 - binary_accuracy: 0.5921\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8235 - binary_accuracy: 0.5921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8224 - binary_accuracy: 0.5921\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8197 - binary_accuracy: 0.4637\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7871 - binary_accuracy: 0.6571\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7654 - binary_accuracy: 0.6791\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7364 - binary_accuracy: 0.6813\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7215 - binary_accuracy: 0.6835\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7042 - binary_accuracy: 0.6835\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7004 - binary_accuracy: 0.6813\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6840 - binary_accuracy: 0.6857\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6788 - binary_accuracy: 0.6835\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6718 - binary_accuracy: 0.6835\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6693 - binary_accuracy: 0.6791\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6652 - binary_accuracy: 0.6813\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6583 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6581 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6557 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6509 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6528 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6488 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6478 - binary_accuracy: 0.6835\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6467 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.6857\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6457 - binary_accuracy: 0.6857\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6451 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - binary_accuracy: 0.6857\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - binary_accuracy: 0.6857\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.6879\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6392 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - binary_accuracy: 0.6857\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - binary_accuracy: 0.6857\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - binary_accuracy: 0.6857\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6389 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6367 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6857\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - binary_accuracy: 0.6857\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6857\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6857\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6879\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6879\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - binary_accuracy: 0.6857\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6358 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6879\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - binary_accuracy: 0.6879\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6857\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6879\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6879\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6857\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - binary_accuracy: 0.6813\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6857\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6813\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6857\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - binary_accuracy: 0.6879\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6857\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6879\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6314 - binary_accuracy: 0.6857\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6879\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6813\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6295 - binary_accuracy: 0.6901\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6857\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6309 - binary_accuracy: 0.6879\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6879\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6879\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6857\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - binary_accuracy: 0.6901\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6901\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6309 - binary_accuracy: 0.6879\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6879\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6879\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6857\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.6857\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6857\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6301 - binary_accuracy: 0.6857\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6317 - binary_accuracy: 0.6879\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_accuracy: 0.6835\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6879\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6879\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6283 - binary_accuracy: 0.6901\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6308 - binary_accuracy: 0.6879\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - binary_accuracy: 0.6879\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6274 - binary_accuracy: 0.6923\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6857\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8465 - binary_accuracy: 0.5275\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8207 - binary_accuracy: 0.5956\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8037 - binary_accuracy: 0.6154\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7941 - binary_accuracy: 0.6352\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7881 - binary_accuracy: 0.6352\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7749 - binary_accuracy: 0.6396\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7719 - binary_accuracy: 0.6374\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7643 - binary_accuracy: 0.6374\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - binary_accuracy: 0.6374\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - binary_accuracy: 0.6352\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - binary_accuracy: 0.6374\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7491 - binary_accuracy: 0.6374\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - binary_accuracy: 0.6418\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - binary_accuracy: 0.6418\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - binary_accuracy: 0.6374\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - binary_accuracy: 0.6396\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7326 - binary_accuracy: 0.6418\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7342 - binary_accuracy: 0.6418\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7304 - binary_accuracy: 0.6418\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7310 - binary_accuracy: 0.6418\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7275 - binary_accuracy: 0.6418\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7266 - binary_accuracy: 0.6418\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7265 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7249 - binary_accuracy: 0.6418\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7242 - binary_accuracy: 0.6418\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7255 - binary_accuracy: 0.6418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7244 - binary_accuracy: 0.6418\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7237 - binary_accuracy: 0.6418\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7218 - binary_accuracy: 0.6418\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7196 - binary_accuracy: 0.6418\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7165 - binary_accuracy: 0.6418\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7199 - binary_accuracy: 0.6418\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7186 - binary_accuracy: 0.6418\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7181 - binary_accuracy: 0.6418\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7189 - binary_accuracy: 0.6418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7198 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7194 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7216 - binary_accuracy: 0.6418\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7343 - binary_accuracy: 0.6418\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7203 - binary_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7163 - binary_accuracy: 0.6440\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7166 - binary_accuracy: 0.6418\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7216 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7145 - binary_accuracy: 0.6396\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7025 - binary_accuracy: 0.6462\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7104 - binary_accuracy: 0.6462\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7007 - binary_accuracy: 0.6505\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7100 - binary_accuracy: 0.6462\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7282 - binary_accuracy: 0.6418\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7215 - binary_accuracy: 0.6418\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7218 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7208 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7233 - binary_accuracy: 0.6418\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7216 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7228 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7231 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7213 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7217 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7201 - binary_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7197 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7216 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7203 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7213 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7221 - binary_accuracy: 0.6418\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7200 - binary_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7183 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7212 - binary_accuracy: 0.6418\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7195 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7190 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7192 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7191 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7197 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7201 - binary_accuracy: 0.6418\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7190 - binary_accuracy: 0.6418\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7199 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7191 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7184 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7184 - binary_accuracy: 0.6418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7189 - binary_accuracy: 0.6418\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7180 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7191 - binary_accuracy: 0.6418\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7178 - binary_accuracy: 0.6418\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7191 - binary_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7181 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7188 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7186 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7186 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7180 - binary_accuracy: 0.6418\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7182 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7177 - binary_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7182 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7184 - binary_accuracy: 0.6418\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7181 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7175 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7181 - binary_accuracy: 0.6418\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7178 - binary_accuracy: 0.6418\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7180 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 4ms/step - loss: 0.8729 - binary_accuracy: 0.5626\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8557 - binary_accuracy: 0.6110\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8531 - binary_accuracy: 0.5846\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8348 - binary_accuracy: 0.6198\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8260 - binary_accuracy: 0.6198\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8184 - binary_accuracy: 0.6220\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8022 - binary_accuracy: 0.6198\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8009 - binary_accuracy: 0.6220\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7935 - binary_accuracy: 0.6220\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7895 - binary_accuracy: 0.6220\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7856 - binary_accuracy: 0.6220\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7815 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7830 - binary_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7788 - binary_accuracy: 0.6220\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7758 - binary_accuracy: 0.6220\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7744 - binary_accuracy: 0.6220\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7660 - binary_accuracy: 0.6220\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7700 - binary_accuracy: 0.6220\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7686 - binary_accuracy: 0.6220\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7697 - binary_accuracy: 0.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7680 - binary_accuracy: 0.6220\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7710 - binary_accuracy: 0.6220\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7694 - binary_accuracy: 0.6220\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7660 - binary_accuracy: 0.6220\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - binary_accuracy: 0.6220\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7592 - binary_accuracy: 0.6220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7622 - binary_accuracy: 0.6220\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7617 - binary_accuracy: 0.6220\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7617 - binary_accuracy: 0.6220\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7639 - binary_accuracy: 0.6220\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7599 - binary_accuracy: 0.6220\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - binary_accuracy: 0.6220\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7646 - binary_accuracy: 0.6220\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7621 - binary_accuracy: 0.6220\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7611 - binary_accuracy: 0.6220\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7595 - binary_accuracy: 0.6220\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7607 - binary_accuracy: 0.6220\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7608 - binary_accuracy: 0.6220\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7606 - binary_accuracy: 0.6220\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7586 - binary_accuracy: 0.6220\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7589 - binary_accuracy: 0.6220\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7596 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7607 - binary_accuracy: 0.6220\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7600 - binary_accuracy: 0.6220\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7597 - binary_accuracy: 0.6220\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - binary_accuracy: 0.6220\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7601 - binary_accuracy: 0.6220\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7583 - binary_accuracy: 0.6220\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7588 - binary_accuracy: 0.6220\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7601 - binary_accuracy: 0.6220\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7580 - binary_accuracy: 0.6220\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7581 - binary_accuracy: 0.6220\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7593 - binary_accuracy: 0.6220\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7574 - binary_accuracy: 0.6220\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7594 - binary_accuracy: 0.6220\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7589 - binary_accuracy: 0.6220\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7583 - binary_accuracy: 0.6220\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7584 - binary_accuracy: 0.6220\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7575 - binary_accuracy: 0.6220\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - binary_accuracy: 0.6220\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7578 - binary_accuracy: 0.6220\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7588 - binary_accuracy: 0.6220\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7572 - binary_accuracy: 0.6220\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7582 - binary_accuracy: 0.6220\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7585 - binary_accuracy: 0.6220\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7577 - binary_accuracy: 0.6220\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7586 - binary_accuracy: 0.6220\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - binary_accuracy: 0.6220\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7593 - binary_accuracy: 0.6220\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7575 - binary_accuracy: 0.6220\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7582 - binary_accuracy: 0.6220\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - binary_accuracy: 0.6220\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7577 - binary_accuracy: 0.6220\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7580 - binary_accuracy: 0.6220\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7570 - binary_accuracy: 0.6220\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7564 - binary_accuracy: 0.6220\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7577 - binary_accuracy: 0.6220\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7564 - binary_accuracy: 0.6220\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7578 - binary_accuracy: 0.6220\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7571 - binary_accuracy: 0.6220\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7577 - binary_accuracy: 0.6220\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7578 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7567 - binary_accuracy: 0.6220\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7568 - binary_accuracy: 0.6220\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7566 - binary_accuracy: 0.6220\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7580 - binary_accuracy: 0.6220\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7575 - binary_accuracy: 0.6220\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7572 - binary_accuracy: 0.6220\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7579 - binary_accuracy: 0.6220\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7578 - binary_accuracy: 0.6220\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - binary_accuracy: 0.6220\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7566 - binary_accuracy: 0.6220\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7567 - binary_accuracy: 0.6220\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7570 - binary_accuracy: 0.6220\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7573 - binary_accuracy: 0.6220\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - binary_accuracy: 0.6220\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - binary_accuracy: 0.6220\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - binary_accuracy: 0.6220\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - binary_accuracy: 0.6220\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7557 - binary_accuracy: 0.6220\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.9017 - binary_accuracy: 0.4835\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8985 - binary_accuracy: 0.5253\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8893 - binary_accuracy: 0.5560\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8828 - binary_accuracy: 0.5846\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8706 - binary_accuracy: 0.5934\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8692 - binary_accuracy: 0.5934\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8628 - binary_accuracy: 0.5934\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8487 - binary_accuracy: 0.5978\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8394 - binary_accuracy: 0.5956\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8404 - binary_accuracy: 0.5934\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8504 - binary_accuracy: 0.5934\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8448 - binary_accuracy: 0.5956\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8403 - binary_accuracy: 0.5978\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8273 - binary_accuracy: 0.5956\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8216 - binary_accuracy: 0.5956\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8193 - binary_accuracy: 0.5956\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8211 - binary_accuracy: 0.5956\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8157 - binary_accuracy: 0.5956\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8160 - binary_accuracy: 0.5978\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8190 - binary_accuracy: 0.5956\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8128 - binary_accuracy: 0.5956\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8118 - binary_accuracy: 0.5956\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8117 - binary_accuracy: 0.5978\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8152 - binary_accuracy: 0.6000\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5978\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8180 - binary_accuracy: 0.5912\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8105 - binary_accuracy: 0.5978\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8123 - binary_accuracy: 0.6022\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8026 - binary_accuracy: 0.5956\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8016 - binary_accuracy: 0.6044\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8013 - binary_accuracy: 0.6066\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8054 - binary_accuracy: 0.6066\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8031 - binary_accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7933 - binary_accuracy: 0.6176\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7814 - binary_accuracy: 0.6154\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7715 - binary_accuracy: 0.6615\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7858 - binary_accuracy: 0.6440\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7770 - binary_accuracy: 0.6593\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7592 - binary_accuracy: 0.6571\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7875 - binary_accuracy: 0.6549\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7652 - binary_accuracy: 0.6747\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7908 - binary_accuracy: 0.6154\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7649 - binary_accuracy: 0.6593\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7611 - binary_accuracy: 0.6681\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7717 - binary_accuracy: 0.6484\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7774 - binary_accuracy: 0.6440\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7736 - binary_accuracy: 0.6681\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8068 - binary_accuracy: 0.6066\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7988 - binary_accuracy: 0.6132\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - binary_accuracy: 0.6593\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7716 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7641 - binary_accuracy: 0.6505\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7584 - binary_accuracy: 0.6615\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7749 - binary_accuracy: 0.6484\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7652 - binary_accuracy: 0.6549\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7719 - binary_accuracy: 0.6571\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7787 - binary_accuracy: 0.6308\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7482 - binary_accuracy: 0.6857\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7479 - binary_accuracy: 0.6659\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7805 - binary_accuracy: 0.6330\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7699 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - binary_accuracy: 0.6747\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7682 - binary_accuracy: 0.6615\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - binary_accuracy: 0.6747\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7705 - binary_accuracy: 0.6396\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7866 - binary_accuracy: 0.6286\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7998 - binary_accuracy: 0.6154\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7740 - binary_accuracy: 0.6396\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7600 - binary_accuracy: 0.6593\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - binary_accuracy: 0.6637\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7508 - binary_accuracy: 0.6637\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8212 - binary_accuracy: 0.5912\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8297 - binary_accuracy: 0.5692\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7986 - binary_accuracy: 0.6022\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8084 - binary_accuracy: 0.5978\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8116 - binary_accuracy: 0.5868\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8038 - binary_accuracy: 0.6088\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8017 - binary_accuracy: 0.5978\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - binary_accuracy: 0.6857\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7561 - binary_accuracy: 0.6593\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7725 - binary_accuracy: 0.6396\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7733 - binary_accuracy: 0.6330\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7548 - binary_accuracy: 0.6725\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7742 - binary_accuracy: 0.6352\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7851 - binary_accuracy: 0.6286\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7803 - binary_accuracy: 0.6264\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7976 - binary_accuracy: 0.6088\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7686 - binary_accuracy: 0.6484\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7825 - binary_accuracy: 0.6264\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7629 - binary_accuracy: 0.6484\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7522 - binary_accuracy: 0.6505\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7552 - binary_accuracy: 0.6571\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7584 - binary_accuracy: 0.6549\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7724 - binary_accuracy: 0.6330\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7880 - binary_accuracy: 0.6330\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7686 - binary_accuracy: 0.6484\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7650 - binary_accuracy: 0.6462\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - binary_accuracy: 0.6703\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7493 - binary_accuracy: 0.6703\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7443 - binary_accuracy: 0.6681\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.9083 - binary_accuracy: 0.5022\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9021 - binary_accuracy: 0.5746\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8952 - binary_accuracy: 0.6228\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8845 - binary_accuracy: 0.6469\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8825 - binary_accuracy: 0.5965\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8691 - binary_accuracy: 0.6162\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8575 - binary_accuracy: 0.6469\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8504 - binary_accuracy: 0.6382\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8403 - binary_accuracy: 0.6557\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8399 - binary_accuracy: 0.6711\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8217 - binary_accuracy: 0.6425\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8167 - binary_accuracy: 0.6447\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8042 - binary_accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7993 - binary_accuracy: 0.6842\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8020 - binary_accuracy: 0.6711\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7914 - binary_accuracy: 0.6711\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7783 - binary_accuracy: 0.6930\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7935 - binary_accuracy: 0.6469\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7777 - binary_accuracy: 0.6535\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7686 - binary_accuracy: 0.6732\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7620 - binary_accuracy: 0.6930\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7674 - binary_accuracy: 0.6732\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7710 - binary_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7819 - binary_accuracy: 0.6579\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7692 - binary_accuracy: 0.6732\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7580 - binary_accuracy: 0.6711\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - binary_accuracy: 0.6776\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7926 - binary_accuracy: 0.6294\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8085 - binary_accuracy: 0.5943\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8042 - binary_accuracy: 0.6009\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8001 - binary_accuracy: 0.6031\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7723 - binary_accuracy: 0.6601\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7672 - binary_accuracy: 0.6711\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7666 - binary_accuracy: 0.6623\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7795 - binary_accuracy: 0.6623\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7958 - binary_accuracy: 0.6206\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7899 - binary_accuracy: 0.6469\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7686 - binary_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7529 - binary_accuracy: 0.6820\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7866 - binary_accuracy: 0.6382\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7576 - binary_accuracy: 0.6579\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - binary_accuracy: 0.6886\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - binary_accuracy: 0.6776\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7630 - binary_accuracy: 0.6623\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7861 - binary_accuracy: 0.6228\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7730 - binary_accuracy: 0.6469\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - binary_accuracy: 0.6842\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7260 - binary_accuracy: 0.7083\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7432 - binary_accuracy: 0.6820\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7375 - binary_accuracy: 0.7018\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - binary_accuracy: 0.6952\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7293 - binary_accuracy: 0.7061\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7278 - binary_accuracy: 0.7127\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6990 - binary_accuracy: 0.7368\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7044 - binary_accuracy: 0.7368\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7143 - binary_accuracy: 0.7105\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7284 - binary_accuracy: 0.7039\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - binary_accuracy: 0.6820\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - binary_accuracy: 0.6820\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7140 - binary_accuracy: 0.7171\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7328 - binary_accuracy: 0.6952\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7077 - binary_accuracy: 0.7215\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7089 - binary_accuracy: 0.7171\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7283 - binary_accuracy: 0.6864\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7309 - binary_accuracy: 0.6864\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7255 - binary_accuracy: 0.6996\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7012 - binary_accuracy: 0.7193\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7157 - binary_accuracy: 0.7039\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7225 - binary_accuracy: 0.7039\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6968 - binary_accuracy: 0.7237\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6870 - binary_accuracy: 0.7412\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7068 - binary_accuracy: 0.7061\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7024 - binary_accuracy: 0.7105\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7445 - binary_accuracy: 0.6645\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7299 - binary_accuracy: 0.6820\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7141 - binary_accuracy: 0.7018\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7059 - binary_accuracy: 0.7149\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6938 - binary_accuracy: 0.7215\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7105 - binary_accuracy: 0.7061\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7170 - binary_accuracy: 0.6952\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6854 - binary_accuracy: 0.7303\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7187 - binary_accuracy: 0.7061\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7054 - binary_accuracy: 0.7259\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7104 - binary_accuracy: 0.7171\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7168 - binary_accuracy: 0.7039\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7099 - binary_accuracy: 0.7105\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7197 - binary_accuracy: 0.7018\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7104 - binary_accuracy: 0.7127\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7579 - binary_accuracy: 0.6535\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7650 - binary_accuracy: 0.6491\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7193 - binary_accuracy: 0.7083\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7151 - binary_accuracy: 0.7083\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7233 - binary_accuracy: 0.6952\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6766 - binary_accuracy: 0.7566\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7072 - binary_accuracy: 0.7127\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - binary_accuracy: 0.6732\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - binary_accuracy: 0.6513\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7751 - binary_accuracy: 0.6360\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7716 - binary_accuracy: 0.6491\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - binary_accuracy: 0.6645\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8073 - binary_accuracy: 0.6110\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8026 - binary_accuracy: 0.6681\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7978 - binary_accuracy: 0.6791\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8007 - binary_accuracy: 0.6659\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8001 - binary_accuracy: 0.6747\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7944 - binary_accuracy: 0.6747\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7880 - binary_accuracy: 0.6835\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7830 - binary_accuracy: 0.6835\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7808 - binary_accuracy: 0.6813\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7749 - binary_accuracy: 0.6879\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7702 - binary_accuracy: 0.6857\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7657 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7615 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7572 - binary_accuracy: 0.6857\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7515 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - binary_accuracy: 0.6835\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7301 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7299 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7230 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7202 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7184 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7159 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7125 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7105 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7096 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7058 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6995 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7004 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6996 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6941 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6925 - binary_accuracy: 0.6835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6912 - binary_accuracy: 0.6813\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6874 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6888 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6865 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6877 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6798 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6805 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6795 - binary_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6772 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6832 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6712 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6757 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6732 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6722 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6736 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6707 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6693 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6712 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6688 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6680 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6625 - binary_accuracy: 0.6835\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6689 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6643 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6653 - binary_accuracy: 0.6835\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6644 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6635 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6638 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6615 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6639 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6633 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6633 - binary_accuracy: 0.6835\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6627 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6607 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6585 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6590 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6570 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6586 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6579 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6563 - binary_accuracy: 0.6835\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6576 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6572 - binary_accuracy: 0.6835\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6569 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6566 - binary_accuracy: 0.6835\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6562 - binary_accuracy: 0.6835\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6561 - binary_accuracy: 0.6835\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6554 - binary_accuracy: 0.6835\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6525 - binary_accuracy: 0.6835\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6542 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6520 - binary_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6542 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_accuracy: 0.6835\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6516 - binary_accuracy: 0.6835\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - binary_accuracy: 0.6835\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6519 - binary_accuracy: 0.6835\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6835\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6502 - binary_accuracy: 0.6835\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6507 - binary_accuracy: 0.6835\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6511 - binary_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - binary_accuracy: 0.6835\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - binary_accuracy: 0.6835\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8489 - binary_accuracy: 0.5912\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8384 - binary_accuracy: 0.6110\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8305 - binary_accuracy: 0.6198\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8184 - binary_accuracy: 0.6198\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8161 - binary_accuracy: 0.6308\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8134 - binary_accuracy: 0.6308\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8056 - binary_accuracy: 0.6352\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8007 - binary_accuracy: 0.6330\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7968 - binary_accuracy: 0.6264\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7923 - binary_accuracy: 0.6330\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7882 - binary_accuracy: 0.6308\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7805 - binary_accuracy: 0.6330\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7813 - binary_accuracy: 0.6374\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7751 - binary_accuracy: 0.6286\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7748 - binary_accuracy: 0.6374\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7832 - binary_accuracy: 0.6352\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7689 - binary_accuracy: 0.6308\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7667 - binary_accuracy: 0.6374\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7656 - binary_accuracy: 0.6330\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7618 - binary_accuracy: 0.6374\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7649 - binary_accuracy: 0.6286\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7637 - binary_accuracy: 0.6374\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7601 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7528 - binary_accuracy: 0.6374\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7626 - binary_accuracy: 0.6286\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7614 - binary_accuracy: 0.6330\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7567 - binary_accuracy: 0.6352\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7550 - binary_accuracy: 0.6352\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7515 - binary_accuracy: 0.6396\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7556 - binary_accuracy: 0.6330\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7493 - binary_accuracy: 0.6374\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7557 - binary_accuracy: 0.6374\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7535 - binary_accuracy: 0.6330\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7489 - binary_accuracy: 0.6396\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7510 - binary_accuracy: 0.6396\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7560 - binary_accuracy: 0.6374\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7526 - binary_accuracy: 0.6352\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7501 - binary_accuracy: 0.6374\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - binary_accuracy: 0.6374\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - binary_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7527 - binary_accuracy: 0.6352\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - binary_accuracy: 0.6396\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - binary_accuracy: 0.6396\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - binary_accuracy: 0.6374\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - binary_accuracy: 0.6396\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7447 - binary_accuracy: 0.6396\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - binary_accuracy: 0.6352\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - binary_accuracy: 0.6396\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - binary_accuracy: 0.6374\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7471 - binary_accuracy: 0.6396\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7394 - binary_accuracy: 0.6352\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7397 - binary_accuracy: 0.6396\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7403 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7391 - binary_accuracy: 0.6374\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7398 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7409 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7355 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7384 - binary_accuracy: 0.6396\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7357 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7376 - binary_accuracy: 0.6396\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7382 - binary_accuracy: 0.6396\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7344 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7410 - binary_accuracy: 0.6374\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7364 - binary_accuracy: 0.6396\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7373 - binary_accuracy: 0.6374\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7412 - binary_accuracy: 0.6352\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7351 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7376 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7358 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7368 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7326 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7338 - binary_accuracy: 0.6396\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7343 - binary_accuracy: 0.6396\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7341 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7365 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7339 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7371 - binary_accuracy: 0.6374\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7343 - binary_accuracy: 0.6396\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7321 - binary_accuracy: 0.6396\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7333 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7340 - binary_accuracy: 0.6374\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7343 - binary_accuracy: 0.6374\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7311 - binary_accuracy: 0.6396\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7275 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7328 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7345 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7303 - binary_accuracy: 0.6396\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7328 - binary_accuracy: 0.6396\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7330 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7350 - binary_accuracy: 0.6396\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7336 - binary_accuracy: 0.6418\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7296 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7299 - binary_accuracy: 0.6396\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7316 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7313 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7336 - binary_accuracy: 0.6396\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7318 - binary_accuracy: 0.6396\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7294 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8738 - binary_accuracy: 0.5253\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8683 - binary_accuracy: 0.5560\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8637 - binary_accuracy: 0.5890\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8559 - binary_accuracy: 0.5934\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8506 - binary_accuracy: 0.6022\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8482 - binary_accuracy: 0.6132\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8423 - binary_accuracy: 0.6088\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8373 - binary_accuracy: 0.6110\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8338 - binary_accuracy: 0.6154\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8303 - binary_accuracy: 0.6132\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8249 - binary_accuracy: 0.6066\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8153 - binary_accuracy: 0.6154\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8199 - binary_accuracy: 0.6198\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8150 - binary_accuracy: 0.6110\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8186 - binary_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8114 - binary_accuracy: 0.6176\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8134 - binary_accuracy: 0.6110\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8086 - binary_accuracy: 0.6154\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8092 - binary_accuracy: 0.6176\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8072 - binary_accuracy: 0.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8024 - binary_accuracy: 0.6176\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8055 - binary_accuracy: 0.6176\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7981 - binary_accuracy: 0.6176\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8030 - binary_accuracy: 0.6198\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7994 - binary_accuracy: 0.6176\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7992 - binary_accuracy: 0.6176\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7981 - binary_accuracy: 0.6176\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7916 - binary_accuracy: 0.6198\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7911 - binary_accuracy: 0.6198\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7911 - binary_accuracy: 0.6176\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7955 - binary_accuracy: 0.6176\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7923 - binary_accuracy: 0.6154\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7901 - binary_accuracy: 0.6220\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7866 - binary_accuracy: 0.6132\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7919 - binary_accuracy: 0.6176\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7891 - binary_accuracy: 0.6220\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7815 - binary_accuracy: 0.6220\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7860 - binary_accuracy: 0.6198\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7846 - binary_accuracy: 0.6242\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7890 - binary_accuracy: 0.6198\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7851 - binary_accuracy: 0.6198\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7821 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7811 - binary_accuracy: 0.6242\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7770 - binary_accuracy: 0.6176\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7801 - binary_accuracy: 0.6242\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7867 - binary_accuracy: 0.6154\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7747 - binary_accuracy: 0.6242\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7772 - binary_accuracy: 0.6242\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7777 - binary_accuracy: 0.6264\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7742 - binary_accuracy: 0.6220\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7800 - binary_accuracy: 0.6220\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7814 - binary_accuracy: 0.6220\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7798 - binary_accuracy: 0.6176\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7837 - binary_accuracy: 0.6198\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7816 - binary_accuracy: 0.6176\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7733 - binary_accuracy: 0.6264\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7752 - binary_accuracy: 0.6242\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7746 - binary_accuracy: 0.6220\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7760 - binary_accuracy: 0.6220\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7780 - binary_accuracy: 0.6220\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7775 - binary_accuracy: 0.6220\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7714 - binary_accuracy: 0.6220\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7715 - binary_accuracy: 0.6176\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7798 - binary_accuracy: 0.6176\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7786 - binary_accuracy: 0.6154\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7785 - binary_accuracy: 0.6220\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7743 - binary_accuracy: 0.6220\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7780 - binary_accuracy: 0.6198\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7753 - binary_accuracy: 0.6198\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7741 - binary_accuracy: 0.6242\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7773 - binary_accuracy: 0.6198\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7763 - binary_accuracy: 0.6176\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7723 - binary_accuracy: 0.6220\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7741 - binary_accuracy: 0.6198\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7756 - binary_accuracy: 0.6220\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7757 - binary_accuracy: 0.6220\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7725 - binary_accuracy: 0.6176\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7739 - binary_accuracy: 0.6176\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7735 - binary_accuracy: 0.6220\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7758 - binary_accuracy: 0.6154\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7737 - binary_accuracy: 0.6198\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7747 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7751 - binary_accuracy: 0.6110\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7758 - binary_accuracy: 0.6176\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7728 - binary_accuracy: 0.6198\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7707 - binary_accuracy: 0.6220\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7711 - binary_accuracy: 0.6220\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7731 - binary_accuracy: 0.6220\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7744 - binary_accuracy: 0.6198\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7731 - binary_accuracy: 0.6154\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7717 - binary_accuracy: 0.6198\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7725 - binary_accuracy: 0.6198\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7720 - binary_accuracy: 0.6176\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7702 - binary_accuracy: 0.6220\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7692 - binary_accuracy: 0.6242\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7688 - binary_accuracy: 0.6264\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7726 - binary_accuracy: 0.6176\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7713 - binary_accuracy: 0.6242\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7705 - binary_accuracy: 0.6198\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7687 - binary_accuracy: 0.6220\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.8952 - binary_accuracy: 0.5516\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8890 - binary_accuracy: 0.5670\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8863 - binary_accuracy: 0.5736\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8850 - binary_accuracy: 0.5758\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8825 - binary_accuracy: 0.5890\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8788 - binary_accuracy: 0.5846\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8732 - binary_accuracy: 0.5890\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8741 - binary_accuracy: 0.5890\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8740 - binary_accuracy: 0.5868\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8661 - binary_accuracy: 0.5890\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8637 - binary_accuracy: 0.5868\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8675 - binary_accuracy: 0.5890\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8648 - binary_accuracy: 0.5868\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8547 - binary_accuracy: 0.5956\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8719 - binary_accuracy: 0.5890\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8731 - binary_accuracy: 0.5890\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8674 - binary_accuracy: 0.5912\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8624 - binary_accuracy: 0.5912\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8641 - binary_accuracy: 0.5912\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8615 - binary_accuracy: 0.5890\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8569 - binary_accuracy: 0.5890\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8576 - binary_accuracy: 0.5890\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8553 - binary_accuracy: 0.5890\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8555 - binary_accuracy: 0.5890\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8519 - binary_accuracy: 0.5912\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8574 - binary_accuracy: 0.5912\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8525 - binary_accuracy: 0.5934\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8451 - binary_accuracy: 0.5912\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8475 - binary_accuracy: 0.5912\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8464 - binary_accuracy: 0.5890\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8485 - binary_accuracy: 0.5912\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8400 - binary_accuracy: 0.5890\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8430 - binary_accuracy: 0.5890\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8445 - binary_accuracy: 0.5912\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8434 - binary_accuracy: 0.5934\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8402 - binary_accuracy: 0.5912\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8396 - binary_accuracy: 0.5890\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8416 - binary_accuracy: 0.5934\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8397 - binary_accuracy: 0.5934\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8413 - binary_accuracy: 0.5912\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8382 - binary_accuracy: 0.5956\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8400 - binary_accuracy: 0.5912\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8359 - binary_accuracy: 0.5890\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8375 - binary_accuracy: 0.5912\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8340 - binary_accuracy: 0.5912\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8344 - binary_accuracy: 0.5890\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8349 - binary_accuracy: 0.5890\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8330 - binary_accuracy: 0.5956\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8335 - binary_accuracy: 0.5956\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8337 - binary_accuracy: 0.5934\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8335 - binary_accuracy: 0.5934\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8265 - binary_accuracy: 0.5912\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8343 - binary_accuracy: 0.5912\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8361 - binary_accuracy: 0.5912\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8326 - binary_accuracy: 0.5890\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8236 - binary_accuracy: 0.5890\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8321 - binary_accuracy: 0.5912\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8326 - binary_accuracy: 0.5912\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8270 - binary_accuracy: 0.5934\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8283 - binary_accuracy: 0.5934\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8248 - binary_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8245 - binary_accuracy: 0.5934\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8279 - binary_accuracy: 0.5934\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8267 - binary_accuracy: 0.5934\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8290 - binary_accuracy: 0.5934\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.5912\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8254 - binary_accuracy: 0.5956\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8259 - binary_accuracy: 0.5956\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8277 - binary_accuracy: 0.5934\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8286 - binary_accuracy: 0.5934\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8234 - binary_accuracy: 0.5978\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8294 - binary_accuracy: 0.5890\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8291 - binary_accuracy: 0.5934\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8230 - binary_accuracy: 0.5934\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8260 - binary_accuracy: 0.5912\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8252 - binary_accuracy: 0.5956\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8219 - binary_accuracy: 0.5934\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8255 - binary_accuracy: 0.5912\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8227 - binary_accuracy: 0.5934\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8216 - binary_accuracy: 0.5934\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.5890\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8219 - binary_accuracy: 0.5978\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8211 - binary_accuracy: 0.5956\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8211 - binary_accuracy: 0.5912\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8248 - binary_accuracy: 0.5890\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8222 - binary_accuracy: 0.5956\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8218 - binary_accuracy: 0.5934\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8187 - binary_accuracy: 0.5956\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8207 - binary_accuracy: 0.5956\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5956\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8200 - binary_accuracy: 0.5934\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8201 - binary_accuracy: 0.5956\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8233 - binary_accuracy: 0.5978\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8224 - binary_accuracy: 0.5978\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8213 - binary_accuracy: 0.5978\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8181 - binary_accuracy: 0.5978\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8166 - binary_accuracy: 0.5978\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8186 - binary_accuracy: 0.5912\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8194 - binary_accuracy: 0.5934\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8190 - binary_accuracy: 0.5956\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.9130 - binary_accuracy: 0.4737\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9050 - binary_accuracy: 0.4978\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9034 - binary_accuracy: 0.5154\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9011 - binary_accuracy: 0.5241\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8982 - binary_accuracy: 0.5219\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8956 - binary_accuracy: 0.5548\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8937 - binary_accuracy: 0.5526\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8907 - binary_accuracy: 0.5592\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8910 - binary_accuracy: 0.5724\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8909 - binary_accuracy: 0.5702\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8860 - binary_accuracy: 0.5789\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8906 - binary_accuracy: 0.5811\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8838 - binary_accuracy: 0.5899\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8845 - binary_accuracy: 0.5899\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8785 - binary_accuracy: 0.5877\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8727 - binary_accuracy: 0.5899\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8717 - binary_accuracy: 0.5921\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8738 - binary_accuracy: 0.5877\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8680 - binary_accuracy: 0.5921\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8676 - binary_accuracy: 0.5921\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8684 - binary_accuracy: 0.5899\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8636 - binary_accuracy: 0.5921\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8643 - binary_accuracy: 0.5899\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8635 - binary_accuracy: 0.5921\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8610 - binary_accuracy: 0.5877\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8616 - binary_accuracy: 0.5921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8557 - binary_accuracy: 0.5899\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8565 - binary_accuracy: 0.5921\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8616 - binary_accuracy: 0.5899\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8558 - binary_accuracy: 0.5921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8580 - binary_accuracy: 0.5921\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8560 - binary_accuracy: 0.5921\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8524 - binary_accuracy: 0.5921\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8491 - binary_accuracy: 0.5921\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8546 - binary_accuracy: 0.5921\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8537 - binary_accuracy: 0.5921\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8527 - binary_accuracy: 0.5921\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8512 - binary_accuracy: 0.5921\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8492 - binary_accuracy: 0.5921\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8487 - binary_accuracy: 0.5921\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8496 - binary_accuracy: 0.5921\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8503 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8478 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8461 - binary_accuracy: 0.5921\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8472 - binary_accuracy: 0.5921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8495 - binary_accuracy: 0.5921\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8435 - binary_accuracy: 0.5921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8398 - binary_accuracy: 0.5921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8463 - binary_accuracy: 0.5921\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8450 - binary_accuracy: 0.5921\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8426 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8413 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8479 - binary_accuracy: 0.5899\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8418 - binary_accuracy: 0.5921\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8414 - binary_accuracy: 0.5921\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8417 - binary_accuracy: 0.5921\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8439 - binary_accuracy: 0.5921\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8397 - binary_accuracy: 0.5921\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8393 - binary_accuracy: 0.5921\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8387 - binary_accuracy: 0.5921\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8334 - binary_accuracy: 0.5921\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8354 - binary_accuracy: 0.5921\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8449 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8399 - binary_accuracy: 0.5921\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8358 - binary_accuracy: 0.5921\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8381 - binary_accuracy: 0.5921\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8348 - binary_accuracy: 0.5921\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8343 - binary_accuracy: 0.5921\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8344 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8340 - binary_accuracy: 0.5921\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8365 - binary_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8328 - binary_accuracy: 0.5921\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8362 - binary_accuracy: 0.5921\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8380 - binary_accuracy: 0.5921\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8367 - binary_accuracy: 0.5921\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8324 - binary_accuracy: 0.5921\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8380 - binary_accuracy: 0.5921\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8334 - binary_accuracy: 0.5921\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8328 - binary_accuracy: 0.5921\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8352 - binary_accuracy: 0.5921\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8350 - binary_accuracy: 0.5921\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8329 - binary_accuracy: 0.5921\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8336 - binary_accuracy: 0.5921\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8324 - binary_accuracy: 0.5921\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8350 - binary_accuracy: 0.5921\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8284 - binary_accuracy: 0.5921\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8329 - binary_accuracy: 0.5921\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8326 - binary_accuracy: 0.5921\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8309 - binary_accuracy: 0.5921\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8300 - binary_accuracy: 0.5921\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8298 - binary_accuracy: 0.5921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8316 - binary_accuracy: 0.5921\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8319 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8323 - binary_accuracy: 0.5921\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8293 - binary_accuracy: 0.5921\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8290 - binary_accuracy: 0.5921\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8308 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8294 - binary_accuracy: 0.5921\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8302 - binary_accuracy: 0.5921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8290 - binary_accuracy: 0.5921\n",
            "Epoch 1/100\n",
            "57/57 [==============================] - 1s 2ms/step - loss: 0.7882 - binary_accuracy: 0.5888\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6375 - binary_accuracy: 0.6274\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6292\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6450\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5875 - binary_accuracy: 0.6485\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5525 - binary_accuracy: 0.6784\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5391 - binary_accuracy: 0.6661\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5121 - binary_accuracy: 0.6872\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4974 - binary_accuracy: 0.7206\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4808 - binary_accuracy: 0.7522\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4727 - binary_accuracy: 0.7364\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4584 - binary_accuracy: 0.7926\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4380 - binary_accuracy: 0.8067\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4441 - binary_accuracy: 0.7996\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4316 - binary_accuracy: 0.7996\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4166 - binary_accuracy: 0.8032\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3852 - binary_accuracy: 0.8330\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3962 - binary_accuracy: 0.8190\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3520 - binary_accuracy: 0.8594\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3984 - binary_accuracy: 0.8418\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3796 - binary_accuracy: 0.8348\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8366\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3576 - binary_accuracy: 0.8348\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3658 - binary_accuracy: 0.8383\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8330\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8366\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3434 - binary_accuracy: 0.8506\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3601 - binary_accuracy: 0.8348\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3385 - binary_accuracy: 0.8471\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3297 - binary_accuracy: 0.8576\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8735\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8506\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8506\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8436\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3332 - binary_accuracy: 0.8576\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3291 - binary_accuracy: 0.8506\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8418\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8471\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3351 - binary_accuracy: 0.8524\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8383\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3089 - binary_accuracy: 0.8752\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8436\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3203 - binary_accuracy: 0.8594\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3660 - binary_accuracy: 0.8436\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8541\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3126 - binary_accuracy: 0.8612\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3460 - binary_accuracy: 0.8524\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3511 - binary_accuracy: 0.8401\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3200 - binary_accuracy: 0.8559\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3238 - binary_accuracy: 0.8559\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2976 - binary_accuracy: 0.8735\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3115 - binary_accuracy: 0.8664\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3713 - binary_accuracy: 0.8330\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3056 - binary_accuracy: 0.8576\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_accuracy: 0.8506\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3229 - binary_accuracy: 0.8559\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3300 - binary_accuracy: 0.8489\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3393 - binary_accuracy: 0.8506\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3210 - binary_accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3260 - binary_accuracy: 0.8594\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3306 - binary_accuracy: 0.8506\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3570 - binary_accuracy: 0.8295\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3367 - binary_accuracy: 0.8576\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8453\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3312 - binary_accuracy: 0.8559\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3453 - binary_accuracy: 0.8489\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8418\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3165 - binary_accuracy: 0.8594\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3144 - binary_accuracy: 0.8594\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3325 - binary_accuracy: 0.8576\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2909 - binary_accuracy: 0.8787\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3299 - binary_accuracy: 0.8576\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2999 - binary_accuracy: 0.8717\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3475 - binary_accuracy: 0.8471\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3004 - binary_accuracy: 0.8682\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2880 - binary_accuracy: 0.8770\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3172 - binary_accuracy: 0.8612\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8330\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2931 - binary_accuracy: 0.8735\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3437 - binary_accuracy: 0.8471\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3390 - binary_accuracy: 0.8471\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3534 - binary_accuracy: 0.8418\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3104 - binary_accuracy: 0.8612\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3341 - binary_accuracy: 0.8506\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3276 - binary_accuracy: 0.8506\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2968 - binary_accuracy: 0.8699\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8436\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3043 - binary_accuracy: 0.8699\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3020 - binary_accuracy: 0.8682\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2952 - binary_accuracy: 0.8699\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3384 - binary_accuracy: 0.8559\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3033 - binary_accuracy: 0.8717\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2958 - binary_accuracy: 0.8735\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3137 - binary_accuracy: 0.8541\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8594\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3352 - binary_accuracy: 0.8524\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3118 - binary_accuracy: 0.8612\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3022 - binary_accuracy: 0.8576\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3039 - binary_accuracy: 0.8699\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3318 - binary_accuracy: 0.8436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melhores_parametros = grid_search.best_params_"
      ],
      "metadata": {
        "id": "zr_FHjHwS6YC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhores_parametros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr_-56lu0DLi",
        "outputId": "24a67f94-a222-40dc-efc2-794f7a980762"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 10,\n",
              " 'epochs': 100,\n",
              " 'kernel_initializer': 'random_uniform',\n",
              " 'loss': 'binary_crossentropy',\n",
              " 'neurons': 8,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_precisao = grid_search.best_score_"
      ],
      "metadata": {
        "id": "NX9cdrTTTBXG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_precisao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdPV4OWl0Gh0",
        "outputId": "1a9fdf75-6c4f-4a67-b7dd-ee118f9853b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9051700046576618"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classificação de somente um registro**"
      ],
      "metadata": {
        "id": "uaIeS5RhaT3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "QWKRyOZkaXek"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = Sequential()\n",
        "classificador.add(Dense(units = 8, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))\n",
        "classificador.add(Dropout(0.2))\n",
        "classificador.add(Dense(units = 8, activation = 'relu', kernel_initializer= 'random_uniform'))\n",
        "classificador.add(Dropout(0.2))\n",
        "#classificadores\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "classificador.compile(optimizer='adam', loss= 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "iPiAC_boPuUM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.fit(previsores, classe, batch_size= 10, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pithUvi-Q9LB",
        "outputId": "96503873-f31d-43ed-dffc-109165330d08"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 3s 2ms/step - loss: 1.3924 - binary_accuracy: 0.5800\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6703 - binary_accuracy: 0.6661\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6942\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5617 - binary_accuracy: 0.7241\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5583 - binary_accuracy: 0.7083\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5270 - binary_accuracy: 0.7329\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4985 - binary_accuracy: 0.7575\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4681 - binary_accuracy: 0.7698\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.4412 - binary_accuracy: 0.8102\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4373 - binary_accuracy: 0.8120\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.4210 - binary_accuracy: 0.8207\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4684 - binary_accuracy: 0.8049\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4216 - binary_accuracy: 0.8366\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3815 - binary_accuracy: 0.8401\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3921 - binary_accuracy: 0.8225\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3796 - binary_accuracy: 0.8524\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3543 - binary_accuracy: 0.8541\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 0.4074 - binary_accuracy: 0.8084\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3881 - binary_accuracy: 0.8278\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.3646 - binary_accuracy: 0.8330\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 1s 9ms/step - loss: 0.3524 - binary_accuracy: 0.8471\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3344 - binary_accuracy: 0.8559\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3484 - binary_accuracy: 0.8330\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3494 - binary_accuracy: 0.8471\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8453\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3382 - binary_accuracy: 0.8594\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8506\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3261 - binary_accuracy: 0.8612\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.3319 - binary_accuracy: 0.8506\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3361 - binary_accuracy: 0.8436\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3613 - binary_accuracy: 0.8418\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.3225 - binary_accuracy: 0.8453\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3212 - binary_accuracy: 0.8612\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3109 - binary_accuracy: 0.8629\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3204 - binary_accuracy: 0.8541\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3500 - binary_accuracy: 0.8401\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3204 - binary_accuracy: 0.8453\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3423 - binary_accuracy: 0.8295\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3176 - binary_accuracy: 0.8594\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3288 - binary_accuracy: 0.8506\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3251 - binary_accuracy: 0.8401\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3305 - binary_accuracy: 0.8559\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3123 - binary_accuracy: 0.8629\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3107 - binary_accuracy: 0.8559\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3035 - binary_accuracy: 0.8576\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8612\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3144 - binary_accuracy: 0.8576\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8524\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3303 - binary_accuracy: 0.8453\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3663 - binary_accuracy: 0.8155\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3151 - binary_accuracy: 0.8506\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2857 - binary_accuracy: 0.8594\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3002 - binary_accuracy: 0.8629\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3001 - binary_accuracy: 0.8559\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3151 - binary_accuracy: 0.8594\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2943 - binary_accuracy: 0.8647\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3349 - binary_accuracy: 0.8559\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8559\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2962 - binary_accuracy: 0.8946\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3025 - binary_accuracy: 0.8699\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2776 - binary_accuracy: 0.8735\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8383\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3138 - binary_accuracy: 0.8471\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2892 - binary_accuracy: 0.8576\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.3035 - binary_accuracy: 0.8418\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3019 - binary_accuracy: 0.8471\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3225 - binary_accuracy: 0.8418\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2864 - binary_accuracy: 0.8629\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3034 - binary_accuracy: 0.8541\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2873 - binary_accuracy: 0.8594\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.3088 - binary_accuracy: 0.8576\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 0.2863 - binary_accuracy: 0.8787\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 9ms/step - loss: 0.2932 - binary_accuracy: 0.8612\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2663 - binary_accuracy: 0.8752\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.2892 - binary_accuracy: 0.8664\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3224 - binary_accuracy: 0.8752\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3195 - binary_accuracy: 0.8647\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3448 - binary_accuracy: 0.8453\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2819 - binary_accuracy: 0.8822\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3028 - binary_accuracy: 0.8805\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2648 - binary_accuracy: 0.8822\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2933 - binary_accuracy: 0.8541\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2890 - binary_accuracy: 0.8594\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 0.2850 - binary_accuracy: 0.8576\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.2734 - binary_accuracy: 0.8612\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.2758 - binary_accuracy: 0.8612\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3199 - binary_accuracy: 0.8682\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3058 - binary_accuracy: 0.8735\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3047 - binary_accuracy: 0.8805\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3171 - binary_accuracy: 0.8699\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3242 - binary_accuracy: 0.8629\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8559\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3183 - binary_accuracy: 0.8559\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2987 - binary_accuracy: 0.8664\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.3710 - binary_accuracy: 0.8225\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3208 - binary_accuracy: 0.8629\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2875 - binary_accuracy: 0.8822\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3187 - binary_accuracy: 0.8682\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3400 - binary_accuracy: 0.8506\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2916 - binary_accuracy: 0.8822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70b6834690>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novo = np.array([[15.80, 8.34, 118, 900, 0.10, 0.26, 0.08, 0.134, 0.178,\n",
        "                  0.20, 0.05, 1098, 0.87, 4500, 145.2, 0.005, 0.04, 0.05, 0.015,\n",
        "                  0.03, 0.007, 23.15, 16.64, 178.5, 2018, 0.14, 0.185, 0.84, 158, 0.363]])"
      ],
      "metadata": {
        "id": "KiKLJxRwSGLP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "novo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoMBXXnmsD3x",
        "outputId": "b06701af-9038-4e49-9af5-874a566a0903"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.580e+01, 8.340e+00, 1.180e+02, 9.000e+02, 1.000e-01, 2.600e-01,\n",
              "        8.000e-02, 1.340e-01, 1.780e-01, 2.000e-01, 5.000e-02, 1.098e+03,\n",
              "        8.700e-01, 4.500e+03, 1.452e+02, 5.000e-03, 4.000e-02, 5.000e-02,\n",
              "        1.500e-02, 3.000e-02, 7.000e-03, 2.315e+01, 1.664e+01, 1.785e+02,\n",
              "        2.018e+03, 1.400e-01, 1.850e-01, 8.400e-01, 1.580e+02, 3.630e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previssao = classificador.predict(novo)"
      ],
      "metadata": {
        "id": "l1qo-QYmsF2Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previssao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIFL0VLvsOYj",
        "outputId": "0d47a2a6-56c7-4375-afd8-c9b846cd4d2e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previssao = (previssao > 0.5)"
      ],
      "metadata": {
        "id": "yI6iBAPNsTxa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previssao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoHmjldMsa0z",
        "outputId": "5d98ba5c-f0c8-43c0-c518-2a9a0869ef44"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salvar a rede neural**"
      ],
      "metadata": {
        "id": "afhTkKeKsjMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "5H7IMuzDsl1b"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kwslsmuis0Oj",
        "outputId": "b933a8a5-825b-4f74-d255-573ebff2032d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e71776e-8959-4820-9b10-1272b6b6bc88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e71776e-8959-4820-9b10-1272b6b6bc88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e71776e-8959-4820-9b10-1272b6b6bc88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e71776e-8959-4820-9b10-1272b6b6bc88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe = pd.read_csv('/content/saidas_breast.csv')\n",
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bkELOsgOs4IS",
        "outputId": "1cd3e1a9-0e48-43be-c2cd-c939cd485a7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f974fac9-aecb-4911-9380-8275fbf53171\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f974fac9-aecb-4911-9380-8275fbf53171')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f974fac9-aecb-4911-9380-8275fbf53171 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f974fac9-aecb-4911-9380-8275fbf53171');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = Sequential()\n",
        "classificador.add(Dense(units = 8, activation = 'relu', kernel_initializer= 'random_uniform', input_dim = 30))\n",
        "classificador.add(Dropout(0.2))\n",
        "classificador.add(Dense(units = 8, activation = 'relu', kernel_initializer= 'random_uniform'))\n",
        "classificador.add(Dropout(0.2))\n",
        "#classificadores\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "classificador.compile(optimizer='adam', loss= 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "classificador.fit(previsores, classe, batch_size= 10, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl__mnLWs5m8",
        "outputId": "3f512a41-646f-4d62-bb34-2fb312283a6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 1s 2ms/step - loss: 1.1916 - binary_accuracy: 0.4903\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6667 - binary_accuracy: 0.5852\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6421 - binary_accuracy: 0.6309\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6221\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6309\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5913 - binary_accuracy: 0.6186\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5705 - binary_accuracy: 0.6467\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5672 - binary_accuracy: 0.6274\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5358 - binary_accuracy: 0.6432\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5126 - binary_accuracy: 0.6942\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.5125 - binary_accuracy: 0.7135\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4885 - binary_accuracy: 0.7170\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4794 - binary_accuracy: 0.7750\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4775 - binary_accuracy: 0.7504\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4511 - binary_accuracy: 0.7786\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.7627\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.7856\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4350 - binary_accuracy: 0.7838\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4322 - binary_accuracy: 0.7856\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4244 - binary_accuracy: 0.7698\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4239 - binary_accuracy: 0.7926\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_accuracy: 0.8243\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4192 - binary_accuracy: 0.7891\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4286 - binary_accuracy: 0.7909\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4066 - binary_accuracy: 0.7961\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3937 - binary_accuracy: 0.7996\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4032 - binary_accuracy: 0.7961\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4044 - binary_accuracy: 0.7979\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4060 - binary_accuracy: 0.7996\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4035 - binary_accuracy: 0.7996\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.4087 - binary_accuracy: 0.7926\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3779 - binary_accuracy: 0.8155\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3674 - binary_accuracy: 0.8278\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3949 - binary_accuracy: 0.8067\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.4026 - binary_accuracy: 0.8014\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3918 - binary_accuracy: 0.8014\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.7891\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3830 - binary_accuracy: 0.8190\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4052 - binary_accuracy: 0.8032\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3984 - binary_accuracy: 0.7944\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3555 - binary_accuracy: 0.8260\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3441 - binary_accuracy: 0.8295\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3749 - binary_accuracy: 0.8014\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3835 - binary_accuracy: 0.8014\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3641 - binary_accuracy: 0.8207\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8102\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3780 - binary_accuracy: 0.8190\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4294 - binary_accuracy: 0.7891\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3517 - binary_accuracy: 0.8330\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3580 - binary_accuracy: 0.8278\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3801 - binary_accuracy: 0.7961\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3759 - binary_accuracy: 0.8032\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3691 - binary_accuracy: 0.7979\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8014\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3637 - binary_accuracy: 0.8137\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3798 - binary_accuracy: 0.8032\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3901 - binary_accuracy: 0.8032\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3706 - binary_accuracy: 0.8155\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8190\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3429 - binary_accuracy: 0.8348\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3820 - binary_accuracy: 0.8102\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3729 - binary_accuracy: 0.8190\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3224 - binary_accuracy: 0.8418\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3958 - binary_accuracy: 0.7961\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4079 - binary_accuracy: 0.8067\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3809 - binary_accuracy: 0.8137\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3793 - binary_accuracy: 0.7996\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3609 - binary_accuracy: 0.8260\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3441 - binary_accuracy: 0.8260\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.8049\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3694 - binary_accuracy: 0.8225\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8243\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3715 - binary_accuracy: 0.7996\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3598 - binary_accuracy: 0.8172\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3468 - binary_accuracy: 0.8348\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3586 - binary_accuracy: 0.8190\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8418\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3483 - binary_accuracy: 0.8207\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8243\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3229 - binary_accuracy: 0.8366\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8278\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3862 - binary_accuracy: 0.8172\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3833 - binary_accuracy: 0.7944\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3544 - binary_accuracy: 0.8137\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8190\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3382 - binary_accuracy: 0.8366\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3565 - binary_accuracy: 0.8295\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3891 - binary_accuracy: 0.8014\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3581 - binary_accuracy: 0.8084\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3114 - binary_accuracy: 0.8682\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3504 - binary_accuracy: 0.8295\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3462 - binary_accuracy: 0.8225\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3687 - binary_accuracy: 0.8172\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3697 - binary_accuracy: 0.8137\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8295\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3888 - binary_accuracy: 0.7996\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4070 - binary_accuracy: 0.7873\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3370 - binary_accuracy: 0.8243\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8225\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70b29628d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_json = classificador.to_json()"
      ],
      "metadata": {
        "id": "hz8zFc7DtKVA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classificador_breast.json', 'w') as json_file:\n",
        "  json_file.write(classificador_json)"
      ],
      "metadata": {
        "id": "7KV8XBn_tQfn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.save_weights('classificador_breast.h5')"
      ],
      "metadata": {
        "id": "D4guXocQthjt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregar a rede neural**"
      ],
      "metadata": {
        "id": "xu7OvU2YuGb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json"
      ],
      "metadata": {
        "id": "FFwrt7LquJbX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arquivo = open('classificador_breast.json', 'r')"
      ],
      "metadata": {
        "id": "IDQwpAjquVp7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estrutura_rede = arquivo.read()"
      ],
      "metadata": {
        "id": "M2a88gPuueIg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estrutura_rede"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "kvJCCkj7unbP",
        "outputId": "b12926a7-0cf2-4014-fee3-943a44727c1c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_644\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 30], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_1932_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1932\", \"trainable\": true, \"batch_input_shape\": [null, 30], \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1288\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1933\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1289\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1934\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.8.0\", \"backend\": \"tensorflow\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arquivo.close()"
      ],
      "metadata": {
        "id": "687DkCRnuqg0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = model_from_json(estrutura_rede)"
      ],
      "metadata": {
        "id": "jMPrgv46utti"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.load_weights('classificador_breast.h5')"
      ],
      "metadata": {
        "id": "gV69G77Tu1jM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "novo = np.array([[15.80, 8.34, 118, 900, 0.10, 0.26, 0.08, 0.134, 0.178,\n",
        "                  0.20, 0.05, 1098, 0.87, 4500, 145.2, 0.005, 0.04, 0.05, 0.015,\n",
        "                  0.03, 0.007, 23.15, 16.64, 178.5, 2018, 0.14, 0.185, 0.84, 158, 0.363]])"
      ],
      "metadata": {
        "id": "TQ6P_5jCvMwj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previssao = classificador.predict(novo)\n",
        "previssao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dniAF2CvvXan",
        "outputId": "92ac5873-1cda-49dc-f107-a558fe7d6e6a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70b28573b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9999994]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previssao = (previssao > 0.5)\n",
        "previssao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z64GLw6SvaRH",
        "outputId": "60dd8d60-d266-46c5-c156-ac51de883852"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "previsores.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aOtGk1scvuzT",
        "outputId": "a122e5ad-ff89-4564-aea0-ab3da0adda5e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
              "0         17.99          10.38           122.80      1001.0           0.11840   \n",
              "1         20.57          17.77           132.90      1326.0           0.08474   \n",
              "2         19.69          21.25           130.00      1203.0           0.10960   \n",
              "3         11.42          20.38            77.58       386.1           0.14250   \n",
              "4         20.29          14.34           135.10      1297.0           0.10030   \n",
              "\n",
              "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
              "0            0.27760           0.3001              0.14710          0.2419   \n",
              "1            0.07864           0.0869              0.07017          0.1812   \n",
              "2            0.15990           0.1974              0.12790          0.2069   \n",
              "3            0.28390           0.2414              0.10520          0.2597   \n",
              "4            0.13280         198.0000              0.10430          0.1809   \n",
              "\n",
              "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
              "0                  0.07871  ...          25.38           17.33   \n",
              "1                  0.05667  ...          24.99           23.41   \n",
              "2                  0.05999  ...          23.57           25.53   \n",
              "3                  0.09744  ...          14.91           26.50   \n",
              "4                  0.05883  ...          22.54           16.67   \n",
              "\n",
              "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
              "0            184.60       2019.0             0.1622              0.6656   \n",
              "1            158.80       1956.0             0.1238              0.1866   \n",
              "2            152.50       1709.0             0.1444              0.4245   \n",
              "3             98.87        567.7             0.2098              0.8663   \n",
              "4            152.20       1575.0             0.1374            205.0000   \n",
              "\n",
              "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
              "0            0.7119                 0.2654           0.4601   \n",
              "1            0.2416               186.0000         275.0000   \n",
              "2            0.4504               243.0000           0.3613   \n",
              "3            0.6869                 0.2575           0.6638   \n",
              "4            0.4000                 0.1625           0.2364   \n",
              "\n",
              "    fractal_dimension_worst  \n",
              "0                   0.11890  \n",
              "1                   0.08902  \n",
              "2                   0.08758  \n",
              "3                 173.00000  \n",
              "4                   0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ddbdfb2-3e70-4954-99c1-f9ccb2dba7e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ddbdfb2-3e70-4954-99c1-f9ccb2dba7e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ddbdfb2-3e70-4954-99c1-f9ccb2dba7e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ddbdfb2-3e70-4954-99c1-f9ccb2dba7e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe = pd.read_csv('/content/saidas_breast.csv')\n",
        "classe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m2moHgwzvxgc",
        "outputId": "33af7c1b-dc7f-4dc7-ea4c-056cb0421b56"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-295fbcd2-da19-4964-83e0-dfc932fe5e38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-295fbcd2-da19-4964-83e0-dfc932fe5e38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-295fbcd2-da19-4964-83e0-dfc932fe5e38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-295fbcd2-da19-4964-83e0-dfc932fe5e38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificador.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
      ],
      "metadata": {
        "id": "FlJUqSVTv0SQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = classificador.evaluate(previsores, classe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87bTmw6_wK1P",
        "outputId": "a1b06d09-bf37-4671-82d7-c9d27ff8a206"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 1s 5ms/step - loss: 0.2223 - binary_accuracy: 0.9350\n"
          ]
        }
      ]
    }
  ]
}